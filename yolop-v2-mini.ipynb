{
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.11"
    },
    "kaggle": {
      "accelerator": "gpu",
      "dataSources": [
        {
          "sourceId": 12345190,
          "sourceType": "datasetVersion",
          "datasetId": 7775335
        }
      ],
      "dockerImageVersionId": 31040,
      "isInternetEnabled": false,
      "language": "python",
      "sourceType": "notebook",
      "isGpuEnabled": true
    },
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "gpuType": "T4",
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/alessela/yolop-v2-mini/blob/main/yolop-v2-mini.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Import libraries"
      ],
      "metadata": {
        "id": "HOUOjqqDCdf4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "import os\n",
        "import random\n",
        "import cv2\n",
        "import numpy as np\n",
        "import gc\n",
        "import zipfile\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torch.utils.data.dataloader import DataLoader\n",
        "from torch.utils.data.dataset import Dataset\n",
        "import torchvision.ops as ops\n",
        "\n",
        "import albumentations as A\n",
        "from albumentations.pytorch import ToTensorV2\n",
        "\n",
        "from sklearn.cluster import KMeans\n",
        "\n",
        "from tqdm import tqdm"
      ],
      "metadata": {
        "id": "664_RUUKCdf6",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-07-22T21:57:12.045725Z",
          "iopub.execute_input": "2025-07-22T21:57:12.046361Z",
          "iopub.status.idle": "2025-07-22T21:57:52.700454Z",
          "shell.execute_reply.started": "2025-07-22T21:57:12.046335Z",
          "shell.execute_reply": "2025-07-22T21:57:52.699682Z"
        }
      },
      "outputs": [],
      "execution_count": 1
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Architecture"
      ],
      "metadata": {
        "id": "ew6QVrEyCdf8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Base components"
      ],
      "metadata": {
        "id": "vMUpaLFgCdf8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Conv"
      ],
      "metadata": {
        "id": "Hv5sOCWiCxRI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Conv(nn.Module):\n",
        "    def __init__(self, c_in, c_out, k, s=1, g=1):\n",
        "        super(Conv, self).__init__()\n",
        "\n",
        "        self.layers = nn.Sequential(\n",
        "            nn.Conv2d(c_in, c_out, k, s, (k - 1) // 2, g, bias=False),\n",
        "            nn.BatchNorm2d(c_out),\n",
        "            nn.SiLU(inplace=True)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.layers(x)"
      ],
      "metadata": {
        "id": "SJO2EuhICdf8",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-07-22T21:57:53.012054Z",
          "iopub.execute_input": "2025-07-22T21:57:53.012232Z",
          "iopub.status.idle": "2025-07-22T21:57:53.030139Z",
          "shell.execute_reply.started": "2025-07-22T21:57:53.012218Z",
          "shell.execute_reply": "2025-07-22T21:57:53.029470Z"
        }
      },
      "outputs": [],
      "execution_count": 2
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Downsampling"
      ],
      "metadata": {
        "id": "wI0WQTU_DF2d"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Downsampling(nn.Module):\n",
        "    def __init__(self, c_in, c_out, k):\n",
        "        super(Downsampling, self).__init__()\n",
        "\n",
        "        self.conv1 = nn.Sequential(\n",
        "            Conv(c_in, c_in, 1),\n",
        "            Conv(c_in, c_out // 2, 3, 2)\n",
        "        )\n",
        "\n",
        "        self.conv2 = nn.Sequential(\n",
        "            nn.MaxPool2d(kernel_size=k, stride=k),\n",
        "            Conv(c_in, c_out // 2, 1)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return torch.cat([self.conv1(x), self.conv2(x)], 1)"
      ],
      "metadata": {
        "id": "xwkcJSlUCdf9",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-07-22T21:57:53.030915Z",
          "iopub.execute_input": "2025-07-22T21:57:53.031155Z",
          "iopub.status.idle": "2025-07-22T21:57:53.042735Z",
          "shell.execute_reply.started": "2025-07-22T21:57:53.031134Z",
          "shell.execute_reply": "2025-07-22T21:57:53.042071Z"
        }
      },
      "outputs": [],
      "execution_count": 3
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Backbone"
      ],
      "metadata": {
        "id": "epjTMiEiCdf9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ELAN Block"
      ],
      "metadata": {
        "id": "RlMWlVZDDXP0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class ELANBlock(nn.Module):\n",
        "    def __init__(self, c_in, c_hidden, n_blocks, c_out):\n",
        "        super(ELANBlock, self).__init__()\n",
        "\n",
        "        self.transition_layer = Conv(c_in, c_hidden, 1)\n",
        "        self.base_layer = Conv(c_in, c_hidden, 1)\n",
        "\n",
        "        self.layers = nn.Sequential(*[Conv(c_hidden, c_hidden, 3) for _ in range(n_blocks)])\n",
        "\n",
        "        n_in = (n_blocks // 2 + 2) * c_hidden\n",
        "        self.feature_aggreation = Conv(n_in, c_out, 1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        output = [self.transition_layer(x)]\n",
        "        x = self.base_layer(x)\n",
        "        output.append(x)\n",
        "\n",
        "        for idx, layer in enumerate(self.layers):\n",
        "            x = layer(x)\n",
        "            if idx % 2 == 1:\n",
        "                output.append(x)\n",
        "\n",
        "        output = torch.cat(output, 1)\n",
        "        return self.feature_aggreation(output)"
      ],
      "metadata": {
        "id": "R0FBhC9zCdf9",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-07-22T21:57:53.044927Z",
          "iopub.execute_input": "2025-07-22T21:57:53.045454Z",
          "iopub.status.idle": "2025-07-22T21:57:53.056756Z",
          "shell.execute_reply.started": "2025-07-22T21:57:53.045438Z",
          "shell.execute_reply": "2025-07-22T21:57:53.056139Z"
        }
      },
      "outputs": [],
      "execution_count": 4
    },
    {
      "cell_type": "markdown",
      "source": [
        "### SPPCSPC"
      ],
      "metadata": {
        "id": "EJVJjkTMDfek"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class SPPCSPC(nn.Module):\n",
        "    def __init__(self, c_in, c_out, k=[5, 9, 13]) -> None:\n",
        "        super(SPPCSPC, self).__init__()\n",
        "\n",
        "        self.conv1 = Conv(c_in, c_out, 1)\n",
        "\n",
        "        self.preprocess = nn.Sequential(\n",
        "            Conv(c_in, c_out, 1),\n",
        "            Conv(c_out, c_out, 3),\n",
        "            Conv(c_out, c_out, 1)\n",
        "        )\n",
        "\n",
        "        self.maxpool = nn.ModuleList([nn.MaxPool2d(ki, 1, ki // 2) for ki in k])\n",
        "\n",
        "        self.postprocess = nn.Sequential(\n",
        "            Conv(4 * c_out, c_out, 1),\n",
        "            Conv(c_out, c_out, 3)\n",
        "        )\n",
        "\n",
        "        self.concat = Conv(2 * c_out, c_out, 1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x1 = self.preprocess(x)\n",
        "\n",
        "        y1 = [x1] + [layer(x1) for layer in self.maxpool]\n",
        "        y1 = torch.cat(y1, 1)\n",
        "        y1 = self.postprocess(y1)\n",
        "\n",
        "        y2 = self.conv1(x)\n",
        "\n",
        "        return self.concat(torch.cat([y1, y2], 1))"
      ],
      "metadata": {
        "id": "OD9cMm9ACdf9",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-07-22T21:57:53.057504Z",
          "iopub.execute_input": "2025-07-22T21:57:53.057733Z",
          "iopub.status.idle": "2025-07-22T21:57:53.076515Z",
          "shell.execute_reply.started": "2025-07-22T21:57:53.057713Z",
          "shell.execute_reply": "2025-07-22T21:57:53.075971Z"
        }
      },
      "outputs": [],
      "execution_count": 5
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Backbone"
      ],
      "metadata": {
        "id": "Pt3n2atKDyX1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Backbone(nn.Module):\n",
        "    def __init__(self, c_out_downs = [64, 128, 256, 512],\n",
        "                     c_hidd_elan = [32, 64, 128, 256],\n",
        "                     n_blocks = 6) -> None:\n",
        "        super(Backbone, self).__init__()\n",
        "\n",
        "        self.conv = Conv(3, 32, 3, 2)\n",
        "\n",
        "        n_in = 32\n",
        "        layers = []\n",
        "        for n_out, n_hidd in zip(c_out_downs, c_hidd_elan):\n",
        "            layers.append(nn.Sequential(\n",
        "                Downsampling(n_in, n_out, 2),\n",
        "                ELANBlock(n_out, n_hidd, n_blocks, n_out)\n",
        "            ))\n",
        "            n_in = n_out\n",
        "\n",
        "        self.layers = nn.Sequential(*layers)\n",
        "        self.spp = SPPCSPC(n_in, n_in)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv(x)\n",
        "\n",
        "        output = []\n",
        "        for idx, layer in enumerate(self.layers):\n",
        "            x = layer(x)\n",
        "            if idx > 0:\n",
        "                output.append(x)\n",
        "\n",
        "        output[-1] = self.spp(output[-1])\n",
        "\n",
        "        return output"
      ],
      "metadata": {
        "id": "mCC6i6vGCdf9",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-07-22T21:57:53.077238Z",
          "iopub.execute_input": "2025-07-22T21:57:53.077532Z",
          "iopub.status.idle": "2025-07-22T21:57:53.093082Z",
          "shell.execute_reply.started": "2025-07-22T21:57:53.077513Z",
          "shell.execute_reply": "2025-07-22T21:57:53.092352Z"
        }
      },
      "outputs": [],
      "execution_count": 6
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Neck"
      ],
      "metadata": {
        "id": "vw9BMO-UCdf9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Fuse Feature Module"
      ],
      "metadata": {
        "id": "gfyuugMlD4RE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class FuseFeatureModule(nn.Module):\n",
        "    def __init__(self, c_in, c_out) -> None:\n",
        "        super(FuseFeatureModule, self).__init__()\n",
        "\n",
        "        self.upsample = nn.Upsample(scale_factor=2, mode='nearest')\n",
        "        self.conv1 = Conv(c_in, c_in // 2, 1)\n",
        "        self.conv2 = Conv(c_in, c_in // 2, 1)\n",
        "        self.conv3 = Conv(c_in, c_out, 3)\n",
        "\n",
        "    def forward(self, x):\n",
        "        [x1, x2] = x\n",
        "        x1 = self.upsample(x1)\n",
        "        x1 = self.conv1(x1)\n",
        "        x2 = self.conv2(x2)\n",
        "        concat = torch.cat([x1, x2], 1)\n",
        "        return self.conv3(concat)"
      ],
      "metadata": {
        "id": "a_s4js0TCdf9",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-07-22T21:57:53.093807Z",
          "iopub.execute_input": "2025-07-22T21:57:53.094011Z",
          "iopub.status.idle": "2025-07-22T21:57:53.111250Z",
          "shell.execute_reply.started": "2025-07-22T21:57:53.093997Z",
          "shell.execute_reply": "2025-07-22T21:57:53.110592Z"
        }
      },
      "outputs": [],
      "execution_count": 7
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Neck"
      ],
      "metadata": {
        "id": "juG7DQe0EB_5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Neck(nn.Module):\n",
        "    def __init__(self, c_in=[512, 256, 128], c_out=[256, 128, 128]) -> None:\n",
        "        super(Neck, self).__init__()\n",
        "\n",
        "        self.p5 = Conv(c_in[0], c_out[0], 1)\n",
        "\n",
        "        self.upsampling = nn.ModuleList([\n",
        "            FuseFeatureModule(n_in, n_out)\n",
        "            for n_in, n_out in zip(c_in[1:], c_out[1:])])\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x[::-1]\n",
        "        output = [self.p5(x[0])]\n",
        "\n",
        "        for layer, xi in zip(self.upsampling, x[1:]):\n",
        "            output.append(layer([output[-1], xi]))\n",
        "\n",
        "        return output"
      ],
      "metadata": {
        "id": "trF9FRwHCdf-",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-07-22T21:57:53.111896Z",
          "iopub.execute_input": "2025-07-22T21:57:53.112050Z",
          "iopub.status.idle": "2025-07-22T21:57:53.125460Z",
          "shell.execute_reply.started": "2025-07-22T21:57:53.112039Z",
          "shell.execute_reply": "2025-07-22T21:57:53.124918Z"
        }
      },
      "outputs": [],
      "execution_count": 8
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Drivable area segment head"
      ],
      "metadata": {
        "id": "uOfGGckbCdf-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class DrivableAreaSegmentHead(nn.Module):\n",
        "    def __init__(self, c_in, c_hidd) -> None:\n",
        "        super(DrivableAreaSegmentHead, self).__init__()\n",
        "\n",
        "        next_layers = [Conv(c_in, c_in, 1)]\n",
        "        n_in = c_in\n",
        "        for n_hidd in c_hidd:\n",
        "            next_layers.append(nn.Upsample(scale_factor=2, mode='nearest'))\n",
        "            next_layers.append(Conv(n_in, n_hidd, 3))\n",
        "\n",
        "            n_in = n_hidd\n",
        "\n",
        "        self.next_layers = nn.Sequential(*next_layers)\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.next_layers(x)"
      ],
      "metadata": {
        "id": "0q0iQnNYCdf-",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-07-22T21:57:53.126112Z",
          "iopub.execute_input": "2025-07-22T21:57:53.126294Z",
          "iopub.status.idle": "2025-07-22T21:57:53.140579Z",
          "shell.execute_reply.started": "2025-07-22T21:57:53.126280Z",
          "shell.execute_reply": "2025-07-22T21:57:53.140031Z"
        }
      },
      "outputs": [],
      "execution_count": 9
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Lane segment head"
      ],
      "metadata": {
        "id": "eSuFGAlDFK2v"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class LaneSegmentHead(nn.Module):\n",
        "    def __init__(self, c_in, c_hidd):\n",
        "        super(LaneSegmentHead, self).__init__()\n",
        "\n",
        "        next_layers = [Conv(c_in, c_in, 1)]\n",
        "        n_in = c_in\n",
        "        for n_hidd in c_hidd:\n",
        "            next_layers.append(nn.ConvTranspose2d(n_in, n_hidd, 2, 2, bias=False))\n",
        "            n_in = n_hidd\n",
        "\n",
        "        self.next_layers = nn.Sequential(*next_layers)\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.next_layers(x)"
      ],
      "metadata": {
        "id": "DEXT0I3ACdf-",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-07-22T21:57:53.141221Z",
          "iopub.execute_input": "2025-07-22T21:57:53.141416Z",
          "iopub.status.idle": "2025-07-22T21:57:53.157230Z",
          "shell.execute_reply.started": "2025-07-22T21:57:53.141402Z",
          "shell.execute_reply": "2025-07-22T21:57:53.156610Z"
        }
      },
      "outputs": [],
      "execution_count": 10
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Detection head"
      ],
      "metadata": {
        "id": "GPOvAbc2Cdf-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Path aggregation block"
      ],
      "metadata": {
        "id": "vg12CbkXFXx9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class PathAggregationBlock(nn.Module):\n",
        "    def __init__(self, c_in) -> None:\n",
        "        super(PathAggregationBlock, self).__init__()\n",
        "\n",
        "        self.conv1 = Conv(c_in, c_in, 3, 2)\n",
        "        self.conv2 = Conv(2 * c_in, 2 * c_in, 3)\n",
        "\n",
        "    def forward(self, x):\n",
        "        [x1, x2] = x\n",
        "        x1 = self.conv1(x1)\n",
        "        concat = torch.cat([x1, x2], 1)\n",
        "        return self.conv2(concat)"
      ],
      "metadata": {
        "id": "RUV3i5JJCdf-",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-07-22T21:57:53.157932Z",
          "iopub.execute_input": "2025-07-22T21:57:53.158167Z",
          "iopub.status.idle": "2025-07-22T21:57:53.171134Z",
          "shell.execute_reply.started": "2025-07-22T21:57:53.158147Z",
          "shell.execute_reply": "2025-07-22T21:57:53.170484Z"
        }
      },
      "outputs": [],
      "execution_count": 11
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Path aggregation network"
      ],
      "metadata": {
        "id": "QUArz0BdFqJ0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class PathAggregationNetwork(nn.Module):\n",
        "    def __init__(self, c_in) -> None:\n",
        "        super(PathAggregationNetwork, self).__init__()\n",
        "\n",
        "        self.n3 = Conv(c_in[0], c_in[0], 1)\n",
        "        self.layers = nn.ModuleList([PathAggregationBlock(n_in) for n_in in c_in[1:]])\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x[::-1]\n",
        "        output = [self.n3(x[0])]\n",
        "\n",
        "        for layer, xi in zip(self.layers, x[1:]):\n",
        "            output.append(layer([output[-1], xi]))\n",
        "\n",
        "        return output"
      ],
      "metadata": {
        "id": "ztzv753iCdf-",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-07-22T21:57:53.171834Z",
          "iopub.execute_input": "2025-07-22T21:57:53.172025Z",
          "iopub.status.idle": "2025-07-22T21:57:53.184606Z",
          "shell.execute_reply.started": "2025-07-22T21:57:53.172011Z",
          "shell.execute_reply": "2025-07-22T21:57:53.183956Z"
        }
      },
      "outputs": [],
      "execution_count": 12
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Detect head"
      ],
      "metadata": {
        "id": "jDUHRDgXFsua"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class DetectHead(nn.Module):\n",
        "    def __init__(self, nc, anchors,\n",
        "               c_in=[128, 128, 256], c_h=[128, 256, 512]) -> None:\n",
        "        super(DetectHead, self).__init__()\n",
        "\n",
        "        self.pan = PathAggregationNetwork(c_in)\n",
        "        self.stride = torch.tensor([8, 16, 32])\n",
        "        self.nc = nc\n",
        "        self.no = nc + 5\n",
        "        self.nl = len(anchors)\n",
        "        self.na = len(anchors[0])\n",
        "        self.grid = [torch.zeros(1)] * self.nl\n",
        "        self.register_buffer('anchor_grid', anchors.float().view(self.nl, 1, -1, 1, 1, 2))\n",
        "        self.detectors = nn.ModuleList(\n",
        "            [nn.Conv2d(n_h, self.no * self.na, 1) for n_h in c_h]\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.pan(x)\n",
        "\n",
        "        for i in range(self.nl):\n",
        "            x[i] = self.detectors[i](x[i])\n",
        "            bs, _, ny, nx = x[i].shape\n",
        "\n",
        "            if self.grid[i].shape[2:4] != x[i].shape[2:4]:\n",
        "                self.grid[i] = self.make_grid(nx, ny).to(x[i].device)\n",
        "\n",
        "            x[i] = x[i].view(bs, self.na, self.no, ny, nx).permute(0, 1, 3, 4, 2).contiguous()\n",
        "            x[i][..., 0:2] = (x[i][..., 0:2].sigmoid() + self.grid[i]) * self.stride[i]\n",
        "            x[i][..., 2:4] = (x[i][..., 2:4].sigmoid() ** 2) * self.anchor_grid[i].to(x[i].device)\n",
        "\n",
        "            if not self.training:\n",
        "                x[i][..., 4:] = x[i][..., 4:].sigmoid()\n",
        "\n",
        "            x[i] = x[i].view(bs, -1, self.no)\n",
        "\n",
        "        return torch.cat(x, dim=1)\n",
        "\n",
        "    @staticmethod\n",
        "    def make_grid(nx, ny):\n",
        "        yv, xv = torch.meshgrid([torch.arange(ny), torch.arange(nx)])\n",
        "        return torch.stack((xv, yv), 2).view((1, 1, ny, nx, 2)).float()"
      ],
      "metadata": {
        "id": "F6wcsiXMCdf-",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-07-22T21:57:53.185236Z",
          "iopub.execute_input": "2025-07-22T21:57:53.185633Z",
          "iopub.status.idle": "2025-07-22T21:57:53.200204Z",
          "shell.execute_reply.started": "2025-07-22T21:57:53.185618Z",
          "shell.execute_reply": "2025-07-22T21:57:53.199680Z"
        }
      },
      "outputs": [],
      "execution_count": 13
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Full implementation"
      ],
      "metadata": {
        "id": "MGti2OJdCdf_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "DEFAULT_ANCHORS = torch.tensor([\n",
        "    [(12, 16), (19, 36), (40, 28)],\n",
        "    [(36, 75), (76, 55), (72, 146)],\n",
        "    [(142, 110), (192, 243), (459, 401)]\n",
        "])\n",
        "\n",
        "class YOLOP(nn.Module):\n",
        "    def __init__(self, nc=10, anchors=DEFAULT_ANCHORS):\n",
        "        super(YOLOP, self).__init__()\n",
        "\n",
        "        self.backbone = Backbone()\n",
        "        self.neck = Neck()\n",
        "        self.drivableAreaHead = DrivableAreaSegmentHead(512, [256, 128, 64, 32, 1])\n",
        "        self.laneHead = LaneSegmentHead(128, [64, 32, 1])\n",
        "        self.detectHead = DetectHead(nc, anchors)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.backbone(x)\n",
        "        drivable = self.drivableAreaHead(x[-1])\n",
        "        x = self.neck(x)\n",
        "        lanes = self.laneHead(x[-1])\n",
        "        boxes = self.detectHead(x)\n",
        "\n",
        "        return drivable, lanes, boxes"
      ],
      "metadata": {
        "id": "GsnTXbWlCdf_",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-07-22T21:57:53.200843Z",
          "iopub.execute_input": "2025-07-22T21:57:53.201021Z",
          "iopub.status.idle": "2025-07-22T21:57:53.220853Z",
          "shell.execute_reply.started": "2025-07-22T21:57:53.201008Z",
          "shell.execute_reply": "2025-07-22T21:57:53.220171Z"
        }
      },
      "outputs": [],
      "execution_count": 14
    },
    {
      "cell_type": "code",
      "source": [
        "model = YOLOP()\n",
        "model.eval()\n",
        "x = torch.randint(0, 255, (1, 3, 640, 640)).float()\n",
        "\n",
        "p_drv, p_lanes, p_boxes = model(x)\n",
        "#print(p_drv.shape)\n",
        "#print(p_lanes.shape)\n",
        "#print(p_boxes.shape)\n",
        "print(p_boxes[..., 0:4].min(), p_boxes[..., 0:4].max())\n",
        "print(p_boxes[..., 4].min(), p_boxes[..., 4].max())\n",
        "print(p_boxes[..., 5:].min(), p_boxes[..., 5:].max())\n",
        "\n",
        "del model, x, p_drv, p_lanes, p_boxes\n",
        "torch.cuda.empty_cache()\n",
        "gc.collect()"
      ],
      "metadata": {
        "id": "ycpup8GyCdf_",
        "trusted": true,
        "outputId": "09e79a15-7cde-4ad2-b652-6aa613b21e25",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "execution": {
          "iopub.status.busy": "2025-07-22T21:57:53.221581Z",
          "iopub.execute_input": "2025-07-22T21:57:53.221828Z",
          "iopub.status.idle": "2025-07-22T21:57:54.800822Z",
          "shell.execute_reply.started": "2025-07-22T21:57:53.221808Z",
          "shell.execute_reply": "2025-07-22T21:57:54.800070Z"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/torch/functional.py:554: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at /pytorch/aten/src/ATen/native/TensorShape.cpp:4322.)\n",
            "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(2.8725, grad_fn=<MinBackward1>) tensor(635.9710, grad_fn=<MaxBackward1>)\n",
            "tensor(0.4943, grad_fn=<MinBackward1>) tensor(0.5208, grad_fn=<MaxBackward1>)\n",
            "tensor(0.4787, grad_fn=<MinBackward1>) tensor(0.5217, grad_fn=<MaxBackward1>)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ],
      "execution_count": 15
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Dataset"
      ],
      "metadata": {
        "id": "zVhAr5ruCdf6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Download dataset"
      ],
      "metadata": {
        "id": "zIIYhU38F3ku"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import kagglehub\n",
        "\n",
        "# Download latest version\n",
        "DATASET_PATH = kagglehub.dataset_download(\"alesssaulea/bdd100k\")\n",
        "DATASET_PATH"
      ],
      "metadata": {
        "id": "8OkQW1VtIPqQ",
        "trusted": true,
        "outputId": "a0a3d98a-3a52-4a71-fc6d-76c316589ee1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        },
        "execution": {
          "iopub.status.busy": "2025-07-22T21:57:52.701691Z",
          "iopub.execute_input": "2025-07-22T21:57:52.702394Z",
          "iopub.status.idle": "2025-07-22T21:57:52.942184Z",
          "shell.execute_reply.started": "2025-07-22T21:57:52.702367Z",
          "shell.execute_reply": "2025-07-22T21:57:52.941508Z"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading from https://www.kaggle.com/api/v1/datasets/download/alesssaulea/bdd100k?dataset_version_number=2...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 5.80G/5.80G [02:35<00:00, 40.0MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting files...\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/root/.cache/kagglehub/datasets/alesssaulea/bdd100k/versions/2'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 16
        }
      ],
      "execution_count": 16
    },
    {
      "cell_type": "code",
      "source": [
        "#DATASET_PATH = '/kaggle/input/bdd100k'"
      ],
      "metadata": {
        "id": "iqk1XDCYO3wW",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-07-22T21:57:52.942957Z",
          "iopub.execute_input": "2025-07-22T21:57:52.943209Z",
          "iopub.status.idle": "2025-07-22T21:57:52.946591Z",
          "shell.execute_reply.started": "2025-07-22T21:57:52.943185Z",
          "shell.execute_reply": "2025-07-22T21:57:52.945856Z"
        }
      },
      "outputs": [],
      "execution_count": 17
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Paths"
      ],
      "metadata": {
        "id": "h7JnbMCeCdf7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "IMAGE_TRAIN_PATH = DATASET_PATH + '/images/100k/train'\n",
        "IMAGE_VAL_PATH = DATASET_PATH + '/images/100k/val'\n",
        "\n",
        "DET_TRAIN_PATH = DATASET_PATH + '/labels/det_20/train'\n",
        "DET_VAL_PATH = DATASET_PATH + '/labels/det_20/val'\n",
        "\n",
        "DRIVABLE_TRAIN_PATH = DATASET_PATH + '/labels/drivable/colormaps/train'\n",
        "DRIVABLE_VAL_PATH = DATASET_PATH + '/labels/drivable/colormaps/val'\n",
        "\n",
        "LANE_TRAIN_PATH = DATASET_PATH + '/labels/lane/colormaps/train'\n",
        "LANE_VAL_PATH = DATASET_PATH + '/labels/lane/colormaps/val'"
      ],
      "metadata": {
        "id": "u1yvXYtXCdf7",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-07-22T21:57:52.948449Z",
          "iopub.execute_input": "2025-07-22T21:57:52.948649Z",
          "iopub.status.idle": "2025-07-22T21:57:52.960881Z",
          "shell.execute_reply.started": "2025-07-22T21:57:52.948633Z",
          "shell.execute_reply": "2025-07-22T21:57:52.960222Z"
        }
      },
      "outputs": [],
      "execution_count": 18
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Utils"
      ],
      "metadata": {
        "id": "rp2fRNdRCdf7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "CATEGORY_TO_INT = {\n",
        "  \"bicycle\": 0,\n",
        "  \"bus\": 1,\n",
        "  \"car\": 2,\n",
        "  \"motorcycle\": 3,\n",
        "  \"person\": 4,\n",
        "  \"pedestrian\": 4,\n",
        "  \"rider\": 5,\n",
        "  \"traffic light\": 6,\n",
        "  \"traffic sign\": 7,\n",
        "  \"train\": 8,\n",
        "  \"truck\": 9,\n",
        "  \"trailer\": 9\n",
        "}"
      ],
      "metadata": {
        "id": "EmAi4m5tCdf7",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-07-22T21:57:52.961705Z",
          "iopub.execute_input": "2025-07-22T21:57:52.961957Z",
          "iopub.status.idle": "2025-07-22T21:57:52.975728Z",
          "shell.execute_reply.started": "2025-07-22T21:57:52.961934Z",
          "shell.execute_reply": "2025-07-22T21:57:52.975013Z"
        }
      },
      "outputs": [],
      "execution_count": 19
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Dataset class"
      ],
      "metadata": {
        "id": "dplfIIFDCdf8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class BDD100K(Dataset):\n",
        "    def __init__(self, img_dir, drv_dir, lane_dir, det_dir, out_s, n=0, train=True):\n",
        "        self.img_dir = img_dir\n",
        "        self.drv_dir = drv_dir\n",
        "        self.lane_dir = lane_dir\n",
        "        self.det_dir = det_dir\n",
        "        self.out_s = out_s\n",
        "        self.transform = ToTensorV2()\n",
        "        self.train = train\n",
        "\n",
        "        img_list: list[str] = os.listdir(self.img_dir)\n",
        "        if n > 0:\n",
        "            img_list = random.sample(img_list, n)\n",
        "\n",
        "        self.images = []\n",
        "        for file in tqdm(img_list, total=len(img_list)):\n",
        "            self.images.append(self.load_image(file))\n",
        "\n",
        "        if self.train:\n",
        "            self.anchors = self.generate_anchors()\n",
        "\n",
        "    def load_image(self, file):\n",
        "        img_path = self.img_dir + '/' + file\n",
        "        det_path = self.det_dir + '/' + file.replace('.jpg', '.json')\n",
        "        drv_path = self.drv_dir + '/' + file.replace('.jpg', '.png')\n",
        "        lane_path = self.lane_dir + '/' + file.replace('.jpg', '.png')\n",
        "\n",
        "        img = cv2.imread(img_path)\n",
        "        h, w, _ = img.shape\n",
        "        img = cv2.resize(img, self.out_s)\n",
        "\n",
        "        drv = cv2.imread(drv_path, cv2.IMREAD_GRAYSCALE)\n",
        "        drv = cv2.resize(drv, self.out_s)\n",
        "        drv = (drv > 0).astype(np.float32)\n",
        "\n",
        "        lanes = cv2.imread(lane_path, cv2.IMREAD_GRAYSCALE)\n",
        "        lanes = cv2.resize(lanes, self.out_s)\n",
        "        lanes = (lanes > 0).astype(np.float32)\n",
        "\n",
        "        try:\n",
        "            with open(det_path) as f:\n",
        "                obj = json.load(f)\n",
        "                labels = obj['labels'] if 'labels' in obj else []\n",
        "        except:\n",
        "            labels = []\n",
        "\n",
        "        boxes = []\n",
        "        sw, sh = self.out_s\n",
        "        ratio_x, ratio_y = sw / w, sh / h\n",
        "\n",
        "        for lbl in labels:\n",
        "            if lbl['category'] in CATEGORY_TO_INT:\n",
        "                cat = CATEGORY_TO_INT[lbl['category']]\n",
        "                x1 = lbl['box2d']['x1'] * ratio_x\n",
        "                y1 = lbl['box2d']['y1'] * ratio_y\n",
        "                x2 = lbl['box2d']['x2'] * ratio_x\n",
        "                y2 = lbl['box2d']['y2'] * ratio_y\n",
        "\n",
        "                assert 0 <= x1 <= sw\n",
        "                assert 0 <= y1 <= sh\n",
        "                assert 0 <= x2 <= sw\n",
        "                assert 0 <= y2 <= sh\n",
        "\n",
        "                xc = (x1 + x2) / 2\n",
        "                yc = (y1 + y2) / 2\n",
        "                wb = abs(x1 - x2)\n",
        "                hb = abs(y1 - y2)\n",
        "\n",
        "                boxes.append((xc, yc, wb, hb, cat))\n",
        "\n",
        "        transf = self.transform(image=img, masks=[drv, lanes])\n",
        "        img = transf['image'].float()\n",
        "        drv, lanes = transf['masks']\n",
        "\n",
        "        return [img, drv, lanes, torch.tensor(boxes)]\n",
        "\n",
        "    def generate_anchors(self):\n",
        "        boxes = [[wb, hb] for _, _, _, lbls in self.images for _, _, wb, hb, _ in lbls]\n",
        "        kmeans = KMeans(n_clusters=9, random_state=0)\n",
        "        kmeans.fit(boxes)\n",
        "        anchors = kmeans.cluster_centers_\n",
        "        anchors = anchors[np.argsort(anchors[:, 0] * anchors[:, 1])]\n",
        "        return torch.tensor(anchors).reshape((3, 3, 2)).float()\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        return self.images[index]\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.images)"
      ],
      "metadata": {
        "id": "7FfRETUFCdf8",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-07-22T22:00:10.899720Z",
          "iopub.execute_input": "2025-07-22T22:00:10.900001Z",
          "iopub.status.idle": "2025-07-22T22:00:10.917329Z",
          "shell.execute_reply.started": "2025-07-22T22:00:10.899981Z",
          "shell.execute_reply": "2025-07-22T22:00:10.916582Z"
        }
      },
      "outputs": [],
      "execution_count": 20
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Training"
      ],
      "metadata": {
        "id": "zw1XC7AlCdf_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Setup"
      ],
      "metadata": {
        "id": "-8Pqlp8pCdf_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "device"
      ],
      "metadata": {
        "id": "4uMGCvn0Cdf_",
        "trusted": true,
        "outputId": "d88384d4-e24e-4490-991b-6586a5989df5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "execution": {
          "iopub.status.busy": "2025-07-22T21:57:54.801536Z",
          "iopub.execute_input": "2025-07-22T21:57:54.801742Z",
          "iopub.status.idle": "2025-07-22T21:57:54.869691Z",
          "shell.execute_reply.started": "2025-07-22T21:57:54.801728Z",
          "shell.execute_reply": "2025-07-22T21:57:54.869138Z"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cuda')"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ],
      "execution_count": 21
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = BDD100K(IMAGE_TRAIN_PATH, DRIVABLE_TRAIN_PATH, LANE_TRAIN_PATH, DET_TRAIN_PATH, (640, 640), n=300)"
      ],
      "metadata": {
        "id": "1rsz1183CdgA",
        "trusted": true,
        "outputId": "643ea23a-3658-48fd-8641-2ff5c61a6e6b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "execution": {
          "iopub.status.busy": "2025-07-22T22:00:29.172533Z",
          "iopub.execute_input": "2025-07-22T22:00:29.172824Z",
          "iopub.status.idle": "2025-07-22T22:00:46.518410Z",
          "shell.execute_reply.started": "2025-07-22T22:00:29.172802Z",
          "shell.execute_reply": "2025-07-22T22:00:46.517646Z"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 300/300 [00:07<00:00, 41.00it/s]\n"
          ]
        }
      ],
      "execution_count": 22
    },
    {
      "cell_type": "code",
      "source": [
        "def collate_fn(batch):\n",
        "    imgs, drvs, lanes, lbls = zip(*batch)\n",
        "    return list(imgs), list(drvs), list(lanes), list(lbls)"
      ],
      "metadata": {
        "id": "-U8WPd6mCdgA",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-07-22T21:58:12.265580Z",
          "iopub.execute_input": "2025-07-22T21:58:12.265874Z",
          "iopub.status.idle": "2025-07-22T21:58:12.269773Z",
          "shell.execute_reply.started": "2025-07-22T21:58:12.265850Z",
          "shell.execute_reply": "2025-07-22T21:58:12.269145Z"
        }
      },
      "outputs": [],
      "execution_count": 23
    },
    {
      "cell_type": "code",
      "source": [
        "data_loader = DataLoader(dataset, batch_size=8, shuffle=True, collate_fn=collate_fn)"
      ],
      "metadata": {
        "id": "Mul9FgWmCdgA",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-07-22T21:58:12.270575Z",
          "iopub.execute_input": "2025-07-22T21:58:12.270840Z",
          "iopub.status.idle": "2025-07-22T21:58:12.285721Z",
          "shell.execute_reply.started": "2025-07-22T21:58:12.270811Z",
          "shell.execute_reply": "2025-07-22T21:58:12.284991Z"
        }
      },
      "outputs": [],
      "execution_count": 24
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Loss function"
      ],
      "metadata": {
        "id": "vqbdGvWHCdgA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def xywh_to_xyxy(boxes):\n",
        "    cx, cy, w, h = boxes[:, 0], boxes[:, 1], boxes[:, 2], boxes[:, 3]\n",
        "    return torch.stack([cx - w / 2, cy - h / 2, cx + w / 2, cy + h / 2], dim=1)"
      ],
      "metadata": {
        "id": "n7I69RbECdf7",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-07-22T21:57:52.976448Z",
          "iopub.execute_input": "2025-07-22T21:57:52.977189Z",
          "iopub.status.idle": "2025-07-22T21:57:52.988951Z",
          "shell.execute_reply.started": "2025-07-22T21:57:52.977162Z",
          "shell.execute_reply": "2025-07-22T21:57:52.988451Z"
        }
      },
      "outputs": [],
      "execution_count": 25
    },
    {
      "cell_type": "code",
      "source": [
        "def center_regions(boxes, radius=2.5):\n",
        "    center_w = boxes[:, 2] / radius\n",
        "    center_h = boxes[:, 3] / radius\n",
        "\n",
        "    cx1 = boxes[:, 0] - center_w\n",
        "    cy1 = boxes[:, 1] - center_h\n",
        "    cx2 = boxes[:, 0] + center_w\n",
        "    cy2 = boxes[:, 1] + center_h\n",
        "\n",
        "    return torch.cat([cx1.unsqueeze(1), cy1.unsqueeze(1), cx2.unsqueeze(1), cy2.unsqueeze(1)], dim=1)"
      ],
      "metadata": {
        "id": "VLaA7qxxJ1Sy"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def filter_pred_in_center_region(p_boxes, c_regions):\n",
        "    gt_x1 = c_regions[:, 0].unsqueeze(1)\n",
        "    gt_y1 = c_regions[:, 1].unsqueeze(1)\n",
        "    gt_x2 = c_regions[:, 2].unsqueeze(1)\n",
        "    gt_y2 = c_regions[:, 3].unsqueeze(1)\n",
        "\n",
        "    px = p_boxes[:, 0].unsqueeze(0)\n",
        "    py = p_boxes[:, 1].unsqueeze(0)\n",
        "\n",
        "    in_x = (px >= gt_x1) & (px <= gt_x2)\n",
        "    in_y = (py >= gt_y1) & (py <= gt_y2)\n",
        "\n",
        "    return in_x & in_y"
      ],
      "metadata": {
        "id": "kZrwwYE0bT5M"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def simota(p_boxes, gt_boxes, l_iou=6.0, l_cls=1.0):\n",
        "    num_pred = len(p_boxes)\n",
        "    num_gt = len(gt_boxes)\n",
        "    nc = p_boxes.size(-1) - 5\n",
        "\n",
        "    c_regions = center_regions(gt_boxes)\n",
        "    is_in_center = filter_pred_in_center_region(p_boxes, c_regions)\n",
        "\n",
        "    ious = ops.box_iou(xywh_to_xyxy(gt_boxes[:, :4]), xywh_to_xyxy(p_boxes[:, :4]))\n",
        "    iou_cost = 1 - ious\n",
        "\n",
        "    gt_cls = F.one_hot(gt_boxes[:, 4].long(), nc).unsqueeze(1).repeat(1, num_pred, 1).float()\n",
        "    pred_cls = p_boxes[:, 5:].unsqueeze(0).repeat(num_gt, 1, 1)\n",
        "    cls_cost = ops.sigmoid_focal_loss(pred_cls, gt_cls).sum(-1)\n",
        "\n",
        "    cost = l_iou * iou_cost + l_cls * cls_cost\n",
        "    cost[~is_in_center] = torch.inf\n",
        "\n",
        "    matched_gt_indices = []\n",
        "    matched_pred_indices = []\n",
        "\n",
        "    for i in range(num_gt):\n",
        "        iou_row = ious[i]\n",
        "        top_k = min(10, iou_row.size(0))\n",
        "        topk_ious, _ = torch.topk(iou_row, top_k)\n",
        "\n",
        "        dynamic_k = max(topk_ious.sum().int().item(), 1)\n",
        "\n",
        "        _, topk_cost_idx = torch.topk(cost[i], dynamic_k, largest=False)\n",
        "\n",
        "        matched_pred_indices.append(topk_cost_idx)\n",
        "        matched_gt_indices.append(torch.full_like(topk_cost_idx, i))\n",
        "\n",
        "    matched_pred_indices = torch.cat(matched_pred_indices)\n",
        "    matched_gt_indices = torch.cat(matched_gt_indices)\n",
        "\n",
        "    unique_pred_indices = matched_pred_indices.unique()\n",
        "    final_gt_indices = torch.full_like(unique_pred_indices, -1)\n",
        "\n",
        "    for i, pred_idx in enumerate(unique_pred_indices):\n",
        "        mask = matched_pred_indices == pred_idx\n",
        "        costs = cost[matched_gt_indices[mask], matched_pred_indices[mask]]\n",
        "        min_cost_idx = torch.argmin(costs)\n",
        "        final_gt_indices[i] = matched_gt_indices[mask][min_cost_idx]\n",
        "\n",
        "    matched_preds = p_boxes[unique_pred_indices]\n",
        "    matched_gts = gt_boxes[final_gt_indices]\n",
        "\n",
        "    return unique_pred_indices, final_gt_indices"
      ],
      "metadata": {
        "id": "qxz2YH6WL0GX"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def detection_loss(p_boxes, gt_boxes, l_obj=0.5, l_cls=1.0, l_reg=5.0):\n",
        "    b = len(p_boxes)\n",
        "    reg_loss = torch.tensor(0., device=p_boxes.device)\n",
        "    obj_loss = torch.tensor(0., device=p_boxes.device)\n",
        "    cls_loss = torch.tensor(0., device=p_boxes.device)\n",
        "\n",
        "    for bi in range(b):\n",
        "        p_boxes_i = p_boxes[bi]\n",
        "        gt_boxes_i = gt_boxes[bi]\n",
        "\n",
        "        if len(gt_boxes_i) == 0:\n",
        "            continue\n",
        "\n",
        "        nc = p_boxes_i.size(-1) - 5\n",
        "\n",
        "        unique_pred_indices, final_gt_indices = simota(p_boxes_i, gt_boxes_i)\n",
        "\n",
        "        matched_preds = p_boxes_i[unique_pred_indices]\n",
        "        matched_gts = gt_boxes_i[final_gt_indices]\n",
        "\n",
        "        pred_xyxy = xywh_to_xyxy(matched_preds[:, :4])\n",
        "        gt_xyxy = xywh_to_xyxy(matched_gts[:, :4])\n",
        "        #reg_loss += ops.complete_box_iou_loss(pred_xyxy, gt_xyxy, reduction='mean')\n",
        "        reg_loss += 1 - ops.box_iou(pred_xyxy, gt_xyxy).diag().mean()\n",
        "\n",
        "        obj_target = torch.zeros_like(p_boxes_i[:, 4], device=p_boxes.device)\n",
        "        obj_target[unique_pred_indices] = 1.0\n",
        "        obj_loss += ops.sigmoid_focal_loss(p_boxes_i[:, 4], obj_target, reduction='mean')\n",
        "\n",
        "        gt_cls = F.one_hot(matched_gts[:, 4].long(), nc).float().to(p_boxes.device)\n",
        "        cls_loss += ops.sigmoid_focal_loss(matched_preds[:, 5:], gt_cls, reduction='mean')\n",
        "\n",
        "    return l_obj * obj_loss + l_cls * cls_loss + l_reg * reg_loss\n",
        "\n",
        "def compute_loss(gt_drv, gt_lanes, gt_boxes, p_drv, p_lanes, p_boxes, l_drv=0.2, l_lanes=0.2, l_det=0.75):\n",
        "    det_loss = detection_loss(p_boxes, gt_boxes)\n",
        "    #drv_loss = F.binary_cross_entropy_with_logits(p_drv.squeeze(1), gt_drv, reduction='mean')\n",
        "    #lanes_loss = ops.sigmoid_focal_loss(p_lanes.squeeze(1), gt_lanes, reduction='mean')\n",
        "\n",
        "    #return l_det * det_loss + l_drv * drv_loss + l_lanes * lanes_loss\n",
        "    return det_loss"
      ],
      "metadata": {
        "id": "g3SlKAGlCdgA",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-07-22T21:58:12.286478Z",
          "iopub.execute_input": "2025-07-22T21:58:12.286707Z",
          "iopub.status.idle": "2025-07-22T21:58:12.302995Z",
          "shell.execute_reply.started": "2025-07-22T21:58:12.286693Z",
          "shell.execute_reply": "2025-07-22T21:58:12.302517Z"
        }
      },
      "outputs": [],
      "execution_count": 29
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Metrics"
      ],
      "metadata": {
        "id": "tA-U9Ga6CaTb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def map_recall(pred_batch, gt_batch, iou_th=0.5, conf_th=0.3):\n",
        "    total_tp, total_fp, total_fn = 0, 0, 0\n",
        "\n",
        "    for i in range(len(pred_batch)):\n",
        "        pred = pred_batch[i]\n",
        "        gt = gt_batch[i]\n",
        "\n",
        "        if pred.numel() == 0:\n",
        "            total_fn += len(gt)\n",
        "            continue\n",
        "\n",
        "        pred = pred[pred[:, 4] > conf_th]\n",
        "\n",
        "        if pred.numel() == 0:\n",
        "            total_fn += len(gt)\n",
        "            continue\n",
        "\n",
        "        p_boxes = pred[:, :4]\n",
        "        p_scores = pred[:, 4]\n",
        "        p_cls = pred[:, 5:].argmax(dim=-1)\n",
        "\n",
        "        gt_boxes = gt[:, :4]\n",
        "        gt_cls = gt[:, 4]\n",
        "\n",
        "        ious = ops.box_iou(xywh_to_xyxy(p_boxes), xywh_to_xyxy(gt_boxes))\n",
        "        matched_gt = torch.zeros(len(gt_boxes), dtype=torch.bool) tp, fp = 0, 0 for j in range(len(pred)): max_iou, gt_idx = ious[j].max(0) if max_iou >= iou_th and not matched_gt[gt_idx.item()] and p_cls[j] == gt_cls[gt_idx]: tp += 1 matched_gt[gt_idx.item()] = True else: fp += 1 fn = len(gt_boxes) - matched_gt.sum() total_tp += tp total_fp += fp total_fn += fn precisions[i] = tp / (tp + fp) if tp + fp > 0 else 0 recall = total_tp / (total_tp + total_fn) if total_tp + total_fn > 0 else 0 mean_ap = precisions.mean().item() return mean_ap, recall;"
      ],
      "metadata": {
        "id": "GWUgbWB0D6eQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Training loop"
      ],
      "metadata": {
        "id": "2lgXd21QCdgK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "torch.cuda.empty_cache()\n",
        "gc.collect()"
      ],
      "metadata": {
        "id": "Hjw2jSR1MHLE",
        "trusted": true,
        "outputId": "b61d1426-caf7-49e4-c6aa-4050fed563bd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "execution": {
          "iopub.status.busy": "2025-07-22T21:58:12.303778Z",
          "iopub.execute_input": "2025-07-22T21:58:12.304210Z",
          "iopub.status.idle": "2025-07-22T21:58:12.480898Z",
          "shell.execute_reply.started": "2025-07-22T21:58:12.304193Z",
          "shell.execute_reply": "2025-07-22T21:58:12.480250Z"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ],
      "execution_count": 30
    },
    {
      "cell_type": "code",
      "source": [
        "model = YOLOP(anchors=dataset.anchors).to(device)\n",
        "\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.937, weight_decay=0.005)\n",
        "scheduler = optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer, 10, 2, 1e-5)\n",
        "\n",
        "epochs = 100\n",
        "patience, counter = 5, 0\n",
        "best_loss = float('inf')\n",
        "\n",
        "metric = MeanAveragePrecision(box_format='cxcywh', iou_thresholds=[0.5])\n",
        "\n",
        "for epoch in range(epochs):\n",
        "    metric.reset()\n",
        "    model.train()\n",
        "    epoch_loss = 0\n",
        "\n",
        "    max_conf = torch.tensor(0.).to(device)\n",
        "    max_cls = torch.tensor(0.).to(device)\n",
        "\n",
        "    for images, gt_drv, gt_lanes, gt_boxes in data_loader:\n",
        "        images = torch.stack(images).float().to(device)\n",
        "        gt_drv = torch.stack(gt_drv).to(device)\n",
        "        gt_lanes = torch.stack(gt_lanes).to(device)\n",
        "        gt_boxes = [boxes.to(device) for boxes in gt_boxes]\n",
        "\n",
        "        #forward pass\n",
        "        p_drv, p_lanes, p_boxes = model(images)\n",
        "\n",
        "        max_cls =\n",
        "\n",
        "        print('conf:', p_boxes[..., 4].sigmoid().min(), p_boxes[..., 4].sigmoid().max())\n",
        "        print('cls:', p_boxes[..., 5:].sigmoid().min(), p_boxes[..., 5:].sigmoid().max())\n",
        "\n",
        "        #loss calculation\n",
        "        loss = compute_loss(gt_drv, gt_lanes, gt_boxes, p_drv, p_lanes, p_boxes)\n",
        "\n",
        "        #Backpropagation\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        epoch_loss += loss.item()\n",
        "\n",
        "        del p_drv, p_lanes, p_boxes, loss\n",
        "\n",
        "    if epoch_loss < best_loss:\n",
        "        best_loss = epoch_loss\n",
        "        counter = 0\n",
        "        torch.save(model.state_dict(), \"yolop_v2_mini.pth\")\n",
        "    else:\n",
        "        counter += 1\n",
        "\n",
        "    model.eval()\n",
        "    predictions, targets = [], []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for images, gt_drv, gt_lanes, gt_boxes in tqdm(data_loader):\n",
        "            images = torch.stack(images).float().to(device)\n",
        "            gt_drv = torch.stack(gt_drv).to(device)\n",
        "            gt_lanes = torch.stack(gt_lanes).to(device)\n",
        "            gt_boxes = [boxes.to(device) for boxes in gt_boxes]\n",
        "\n",
        "            #forward pass\n",
        "            p_drv, p_lanes, p_boxes = model(images)\n",
        "\n",
        "            for bi in range(len(images)):\n",
        "                p_boxes_i = p_boxes[bi]\n",
        "                gt_boxes_i = gt_boxes[bi]\n",
        "\n",
        "                conf = p_boxes_i[:, 4] > 0.3\n",
        "                p_boxes_i = p_boxes_i[conf]\n",
        "\n",
        "                keep = ops.nms(xywh_to_xyxy(p_boxes_i[:, :4]), p_boxes_i[:, 4], 0.5)\n",
        "                p_boxes_i = p_boxes_i[keep]\n",
        "\n",
        "                predictions.append({\n",
        "                    'boxes': p_boxes_i[:, :4],\n",
        "                    'scores': p_boxes_i[:, 4],\n",
        "                    'labels': p_boxes_i[:, 5:].argmax(dim=-1)\n",
        "                })\n",
        "\n",
        "                targets.append({\n",
        "                    'boxes': gt_boxes_i[:, :4],\n",
        "                    'labels': gt_boxes_i[:, 4].long()\n",
        "                } if len(gt_boxes_i) > 0 else {\n",
        "                    'boxes': torch.tensor([], device=p_boxes.device),\n",
        "                    'labels': torch.tensor([], device=p_boxes.device)\n",
        "                })\n",
        "\n",
        "            del p_drv, p_lanes, p_boxes\n",
        "\n",
        "    metric.update(predictions, targets)\n",
        "    result = metric.compute()\n",
        "    recall = result['mar_100']\n",
        "    map50 = result['map_50']\n",
        "\n",
        "    print(f\"Epoch {epoch+1}/{epochs}, Loss: {epoch_loss:.4f}, recall: {recall:.4f}, map50: {map50:.4f}\")\n",
        "\n",
        "    if counter >= patience:\n",
        "        print('Training stopped early')\n",
        "        break\n",
        "\n",
        "del model\n",
        "torch.cuda.empty_cache()\n",
        "gc.collect()"
      ],
      "metadata": {
        "id": "q7pl53WwCdgK",
        "trusted": true,
        "outputId": "5571d282-ceec-4728-a1f3-679bf3d660e2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 106
        },
        "execution": {
          "iopub.status.busy": "2025-07-22T21:58:12.483945Z",
          "iopub.execute_input": "2025-07-22T21:58:12.484128Z",
          "iopub.status.idle": "2025-07-22T21:59:02.296286Z",
          "shell.execute_reply.started": "2025-07-22T21:58:12.484113Z",
          "shell.execute_reply": "2025-07-22T21:59:02.295739Z"
        }
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "SyntaxError",
          "evalue": "invalid syntax (ipython-input-3597550871.py, line 29)",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"/tmp/ipython-input-3597550871.py\"\u001b[0;36m, line \u001b[0;32m29\u001b[0m\n\u001b[0;31m    max_cls =\u001b[0m\n\u001b[0m             ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
          ]
        }
      ],
      "execution_count": 31
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Validation"
      ],
      "metadata": {
        "id": "QXUB8nsACdgK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Setup"
      ],
      "metadata": {
        "id": "Zln8TtgqCdgK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "val_dataset = BDD100K(IMAGE_VAL_PATH, DRIVABLE_VAL_PATH, LANE_VAL_PATH, DET_VAL_PATH, (640, 640), 300, False)"
      ],
      "metadata": {
        "id": "GYgDPN3dCdgL",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-07-22T21:59:02.297264Z",
          "iopub.execute_input": "2025-07-22T21:59:02.297483Z",
          "iopub.status.idle": "2025-07-22T21:59:18.554590Z",
          "shell.execute_reply.started": "2025-07-22T21:59:02.297466Z",
          "shell.execute_reply": "2025-07-22T21:59:18.553947Z"
        }
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "val_data_loader = DataLoader(val_dataset, batch_size=8, shuffle=True, collate_fn=collate_fn)"
      ],
      "metadata": {
        "id": "N2ZVDZdlCdgL",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-07-22T21:59:18.555356Z",
          "iopub.execute_input": "2025-07-22T21:59:18.555569Z",
          "iopub.status.idle": "2025-07-22T21:59:18.559262Z",
          "shell.execute_reply.started": "2025-07-22T21:59:18.555553Z",
          "shell.execute_reply": "2025-07-22T21:59:18.558523Z"
        }
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Validation loop"
      ],
      "metadata": {
        "id": "YicRKnVECdgL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "torch.cuda.empty_cache()\n",
        "gc.collect()"
      ],
      "metadata": {
        "id": "wPwLXdhDCdgL",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-07-22T21:59:18.575507Z",
          "iopub.execute_input": "2025-07-22T21:59:18.575708Z",
          "iopub.status.idle": "2025-07-22T21:59:18.755235Z",
          "shell.execute_reply.started": "2025-07-22T21:59:18.575692Z",
          "shell.execute_reply": "2025-07-22T21:59:18.754510Z"
        }
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "model = YOLOP().to(device)\n",
        "model.load_state_dict(torch.load('yolop_v2_mini.pth'))\n",
        "\n",
        "model.eval()\n",
        "\n",
        "recall_score = 0\n",
        "map50_score = 0\n",
        "\n",
        "with torch.no_grad():\n",
        "    for b, (images, gt_drv, gt_lanes, gt_boxes) in enumerate(val_data_loader):\n",
        "        images = torch.stack(images).float().to(device)\n",
        "        gt_drv = torch.stack(gt_drv).to(device)\n",
        "        gt_lanes = torch.stack(gt_lanes).to(device)\n",
        "        gt_boxes = [gt_boxes[i].to(device) for i in range(len(gt_boxes))]\n",
        "\n",
        "        #inference\n",
        "        p_drv, p_lanes, p_boxes = model(images)\n",
        "\n",
        "        #metrics calculation\n",
        "        map_s, recall_s = map_recall(p_boxes, gt_boxes)\n",
        "\n",
        "        recall_score += recall_s\n",
        "        map50_score += map_s\n",
        "\n",
        "        print(f\"Batch {b + 1}/{len(data_loader)} - Recall: {recall_s:.4f}, mAP50: {map_s:.4f}\")\n",
        "\n",
        "        del p_drv, p_lanes, p_boxes\n",
        "\n",
        "recall_score = recall_score / len(data_loader)\n",
        "map50_score = map50_score / len(data_loader)\n",
        "\n",
        "print(f'Total recall: {recall_score:.4f}')\n",
        "print(f'Total mAP50: {map50_score:.4f}')\n",
        "\n",
        "del model\n",
        "torch.cuda.empty_cache()\n",
        "gc.collect()"
      ],
      "metadata": {
        "id": "QVPyYSd0CdgL",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-07-22T21:59:18.756003Z",
          "iopub.execute_input": "2025-07-22T21:59:18.756217Z",
          "iopub.status.idle": "2025-07-22T21:59:19.070445Z",
          "shell.execute_reply.started": "2025-07-22T21:59:18.756202Z",
          "shell.execute_reply": "2025-07-22T21:59:19.069529Z"
        }
      },
      "outputs": [],
      "execution_count": null
    }
  ]
}