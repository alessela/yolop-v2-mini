{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.11"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":12345190,"sourceType":"datasetVersion","datasetId":7775335}],"dockerImageVersionId":31040,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":true},"colab":{"provenance":[],"toc_visible":true,"gpuType":"T4","include_colab_link":true},"accelerator":"GPU"},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"<a href=\"https://colab.research.google.com/github/alessela/yolop-v2-mini/blob/main/yolop-v2-mini.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>","metadata":{"id":"view-in-github","colab_type":"text"}},{"cell_type":"markdown","source":"# Import libraries","metadata":{"id":"HOUOjqqDCdf4"}},{"cell_type":"code","source":"import json\nimport os\nimport random\nimport cv2\nimport numpy as np\nimport gc\nimport zipfile\nimport matplotlib.pyplot as plt\n\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torch.optim as optim\nfrom torch.utils.data.dataloader import DataLoader\nfrom torch.utils.data.dataset import Dataset\nimport torchvision.ops as ops\n\nimport albumentations as A\nfrom albumentations.pytorch import ToTensorV2\n\nfrom sklearn.cluster import KMeans\n\nfrom tqdm import tqdm","metadata":{"id":"664_RUUKCdf6","trusted":true,"execution":{"iopub.status.busy":"2025-08-27T20:33:17.645837Z","iopub.execute_input":"2025-08-27T20:33:17.646061Z","iopub.status.idle":"2025-08-27T20:34:01.135197Z","shell.execute_reply.started":"2025-08-27T20:33:17.646038Z","shell.execute_reply":"2025-08-27T20:34:01.134561Z"}},"outputs":[{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/albumentations/check_version.py:107: UserWarning: Error fetching version info <urlopen error [Errno -3] Temporary failure in name resolution>\n  data = fetch_version_info()\n","output_type":"stream"}],"execution_count":1},{"cell_type":"markdown","source":"# Architecture","metadata":{"id":"ew6QVrEyCdf8"}},{"cell_type":"markdown","source":"## Base components","metadata":{"id":"vMUpaLFgCdf8"}},{"cell_type":"markdown","source":"### Conv","metadata":{"id":"Hv5sOCWiCxRI"}},{"cell_type":"code","source":"class Conv(nn.Module):\n    def __init__(self, c_in, c_out, k, s=1, g=1):\n        super(Conv, self).__init__()\n\n        self.layers = nn.Sequential(\n            nn.Conv2d(c_in, c_out, k, s, (k - 1) // 2, g, bias=False),\n            nn.BatchNorm2d(c_out),\n            nn.SiLU(inplace=True)\n        )\n\n    def forward(self, x):\n        return self.layers(x)","metadata":{"id":"SJO2EuhICdf8","trusted":true,"execution":{"iopub.status.busy":"2025-08-27T20:34:01.136522Z","iopub.execute_input":"2025-08-27T20:34:01.136918Z","iopub.status.idle":"2025-08-27T20:34:01.141949Z","shell.execute_reply.started":"2025-08-27T20:34:01.136898Z","shell.execute_reply":"2025-08-27T20:34:01.141224Z"}},"outputs":[],"execution_count":2},{"cell_type":"markdown","source":"### Downsampling","metadata":{"id":"wI0WQTU_DF2d"}},{"cell_type":"code","source":"class Downsampling(nn.Module):\n    def __init__(self, c_in, c_out, k):\n        super(Downsampling, self).__init__()\n\n        self.conv1 = nn.Sequential(\n            Conv(c_in, c_in, 1),\n            Conv(c_in, c_out // 2, 3, 2)\n        )\n\n        self.conv2 = nn.Sequential(\n            nn.MaxPool2d(kernel_size=k, stride=k),\n            Conv(c_in, c_out // 2, 1)\n        )\n\n    def forward(self, x):\n        return torch.cat([self.conv1(x), self.conv2(x)], 1)","metadata":{"id":"xwkcJSlUCdf9","trusted":true,"execution":{"iopub.status.busy":"2025-08-27T20:34:01.142680Z","iopub.execute_input":"2025-08-27T20:34:01.142902Z","iopub.status.idle":"2025-08-27T20:34:01.185166Z","shell.execute_reply.started":"2025-08-27T20:34:01.142887Z","shell.execute_reply":"2025-08-27T20:34:01.184496Z"}},"outputs":[],"execution_count":3},{"cell_type":"markdown","source":"## Backbone","metadata":{"id":"epjTMiEiCdf9"}},{"cell_type":"markdown","source":"### ELAN Block","metadata":{"id":"RlMWlVZDDXP0"}},{"cell_type":"code","source":"class ELANBlock(nn.Module):\n    def __init__(self, c_in, c_hidden, n_blocks, c_out):\n        super(ELANBlock, self).__init__()\n\n        self.transition_layer = Conv(c_in, c_hidden, 1)\n        self.base_layer = Conv(c_in, c_hidden, 1)\n\n        self.layers = nn.Sequential(*[Conv(c_hidden, c_hidden, 3) for _ in range(n_blocks)])\n\n        n_in = (n_blocks // 2 + 2) * c_hidden\n        self.feature_aggreation = Conv(n_in, c_out, 1)\n\n    def forward(self, x):\n        output = [self.transition_layer(x)]\n        x = self.base_layer(x)\n        output.append(x)\n\n        for idx, layer in enumerate(self.layers):\n            x = layer(x)\n            if idx % 2 == 1:\n                output.append(x)\n\n        output = torch.cat(output, 1)\n        return self.feature_aggreation(output)","metadata":{"id":"R0FBhC9zCdf9","trusted":true,"execution":{"iopub.status.busy":"2025-08-27T20:34:01.185831Z","iopub.execute_input":"2025-08-27T20:34:01.186016Z","iopub.status.idle":"2025-08-27T20:34:01.202314Z","shell.execute_reply.started":"2025-08-27T20:34:01.186000Z","shell.execute_reply":"2025-08-27T20:34:01.201701Z"}},"outputs":[],"execution_count":4},{"cell_type":"markdown","source":"### SPPCSPC","metadata":{"id":"EJVJjkTMDfek"}},{"cell_type":"code","source":"class SPPCSPC(nn.Module):\n    def __init__(self, c_in, c_out, k=[5, 9, 13]) -> None:\n        super(SPPCSPC, self).__init__()\n\n        self.conv1 = Conv(c_in, c_out, 1)\n\n        self.preprocess = nn.Sequential(\n            Conv(c_in, c_out, 1),\n            Conv(c_out, c_out, 3),\n            Conv(c_out, c_out, 1)\n        )\n\n        self.maxpool = nn.ModuleList([nn.MaxPool2d(ki, 1, ki // 2) for ki in k])\n\n        self.postprocess = nn.Sequential(\n            Conv(4 * c_out, c_out, 1),\n            Conv(c_out, c_out, 3)\n        )\n\n        self.concat = Conv(2 * c_out, c_out, 1)\n\n    def forward(self, x):\n        x1 = self.preprocess(x)\n\n        y1 = [x1] + [layer(x1) for layer in self.maxpool]\n        y1 = torch.cat(y1, 1)\n        y1 = self.postprocess(y1)\n\n        y2 = self.conv1(x)\n\n        return self.concat(torch.cat([y1, y2], 1))","metadata":{"id":"OD9cMm9ACdf9","trusted":true,"execution":{"iopub.status.busy":"2025-08-27T20:34:01.202987Z","iopub.execute_input":"2025-08-27T20:34:01.203187Z","iopub.status.idle":"2025-08-27T20:34:01.223207Z","shell.execute_reply.started":"2025-08-27T20:34:01.203172Z","shell.execute_reply":"2025-08-27T20:34:01.222561Z"}},"outputs":[],"execution_count":5},{"cell_type":"markdown","source":"### Backbone","metadata":{"id":"Pt3n2atKDyX1"}},{"cell_type":"code","source":"class Backbone(nn.Module):\n    def __init__(self, c_out_downs = [64, 128, 256, 512],\n                     c_hidd_elan = [32, 64, 128, 256],\n                     n_blocks = 6) -> None:\n        super(Backbone, self).__init__()\n\n        self.conv = Conv(3, 32, 3, 2)\n\n        n_in = 32\n        layers = []\n        for n_out, n_hidd in zip(c_out_downs, c_hidd_elan):\n            layers.append(nn.Sequential(\n                Downsampling(n_in, n_out, 2),\n                ELANBlock(n_out, n_hidd, n_blocks, n_out)\n            ))\n            n_in = n_out\n\n        self.layers = nn.Sequential(*layers)\n        self.spp = SPPCSPC(n_in, n_in)\n\n    def forward(self, x):\n        x = self.conv(x)\n\n        output = []\n        for idx, layer in enumerate(self.layers):\n            x = layer(x)\n            if idx > 0:\n                output.append(x)\n\n        output[-1] = self.spp(output[-1])\n\n        return output","metadata":{"id":"mCC6i6vGCdf9","trusted":true,"execution":{"iopub.status.busy":"2025-08-27T20:34:01.224002Z","iopub.execute_input":"2025-08-27T20:34:01.224677Z","iopub.status.idle":"2025-08-27T20:34:01.238337Z","shell.execute_reply.started":"2025-08-27T20:34:01.224655Z","shell.execute_reply":"2025-08-27T20:34:01.237595Z"}},"outputs":[],"execution_count":6},{"cell_type":"markdown","source":"## Neck","metadata":{"id":"vw9BMO-UCdf9"}},{"cell_type":"markdown","source":"### Fuse Feature Module","metadata":{"id":"gfyuugMlD4RE"}},{"cell_type":"code","source":"class FuseFeatureModule(nn.Module):\n    def __init__(self, c_in, c_out) -> None:\n        super(FuseFeatureModule, self).__init__()\n\n        self.upsample = nn.Upsample(scale_factor=2, mode='nearest')\n        self.conv1 = Conv(c_in, c_in // 2, 1)\n        self.conv2 = Conv(c_in, c_in // 2, 1)\n        self.conv3 = Conv(c_in, c_out, 3)\n\n    def forward(self, x):\n        [x1, x2] = x\n        x1 = self.upsample(x1)\n        x1 = self.conv1(x1)\n        x2 = self.conv2(x2)\n        concat = torch.cat([x1, x2], 1)\n        return self.conv3(concat)","metadata":{"id":"a_s4js0TCdf9","trusted":true,"execution":{"iopub.status.busy":"2025-08-27T20:34:01.240511Z","iopub.execute_input":"2025-08-27T20:34:01.240676Z","iopub.status.idle":"2025-08-27T20:34:01.255335Z","shell.execute_reply.started":"2025-08-27T20:34:01.240663Z","shell.execute_reply":"2025-08-27T20:34:01.254657Z"}},"outputs":[],"execution_count":7},{"cell_type":"markdown","source":"### Neck","metadata":{"id":"juG7DQe0EB_5"}},{"cell_type":"code","source":"class Neck(nn.Module):\n    def __init__(self, c_in=[512, 256, 128], c_out=[256, 128, 128]) -> None:\n        super(Neck, self).__init__()\n\n        self.p5 = Conv(c_in[0], c_out[0], 1)\n\n        self.upsampling = nn.ModuleList([\n            FuseFeatureModule(n_in, n_out)\n            for n_in, n_out in zip(c_in[1:], c_out[1:])])\n\n    def forward(self, x):\n        x = x[::-1]\n        output = [self.p5(x[0])]\n\n        for layer, xi in zip(self.upsampling, x[1:]):\n            output.append(layer([output[-1], xi]))\n\n        return output","metadata":{"id":"trF9FRwHCdf-","trusted":true,"execution":{"iopub.status.busy":"2025-08-27T20:34:01.256044Z","iopub.execute_input":"2025-08-27T20:34:01.256289Z","iopub.status.idle":"2025-08-27T20:34:01.268898Z","shell.execute_reply.started":"2025-08-27T20:34:01.256269Z","shell.execute_reply":"2025-08-27T20:34:01.268402Z"}},"outputs":[],"execution_count":8},{"cell_type":"markdown","source":"## Drivable area segment head","metadata":{"id":"uOfGGckbCdf-"}},{"cell_type":"code","source":"class DrivableAreaSegmentHead(nn.Module):\n    def __init__(self, c_in, c_hidd) -> None:\n        super(DrivableAreaSegmentHead, self).__init__()\n\n        next_layers = [Conv(c_in, c_in, 1)]\n        n_in = c_in\n        for n_hidd in c_hidd:\n            next_layers.append(nn.Upsample(scale_factor=2, mode='nearest'))\n            next_layers.append(Conv(n_in, n_hidd, 3))\n\n            n_in = n_hidd\n\n        self.next_layers = nn.Sequential(*next_layers)\n\n    def forward(self, x):\n        return self.next_layers(x)","metadata":{"id":"0q0iQnNYCdf-","trusted":true,"execution":{"iopub.status.busy":"2025-08-27T20:34:01.269765Z","iopub.execute_input":"2025-08-27T20:34:01.270331Z","iopub.status.idle":"2025-08-27T20:34:01.286303Z","shell.execute_reply.started":"2025-08-27T20:34:01.270310Z","shell.execute_reply":"2025-08-27T20:34:01.285657Z"}},"outputs":[],"execution_count":9},{"cell_type":"markdown","source":"## Lane segment head","metadata":{"id":"eSuFGAlDFK2v"}},{"cell_type":"code","source":"class LaneSegmentHead(nn.Module):\n    def __init__(self, c_in, c_hidd):\n        super(LaneSegmentHead, self).__init__()\n\n        next_layers = [Conv(c_in, c_in, 1)]\n        n_in = c_in\n        for n_hidd in c_hidd:\n            next_layers.append(nn.ConvTranspose2d(n_in, n_hidd, 2, 2, bias=False))\n            n_in = n_hidd\n\n        self.next_layers = nn.Sequential(*next_layers)\n\n    def forward(self, x):\n        return self.next_layers(x)","metadata":{"id":"DEXT0I3ACdf-","trusted":true,"execution":{"iopub.status.busy":"2025-08-27T20:34:01.286914Z","iopub.execute_input":"2025-08-27T20:34:01.287145Z","iopub.status.idle":"2025-08-27T20:34:01.305025Z","shell.execute_reply.started":"2025-08-27T20:34:01.287125Z","shell.execute_reply":"2025-08-27T20:34:01.304210Z"}},"outputs":[],"execution_count":10},{"cell_type":"markdown","source":"## Detection head","metadata":{"id":"GPOvAbc2Cdf-"}},{"cell_type":"markdown","source":"### Path aggregation block","metadata":{"id":"vg12CbkXFXx9"}},{"cell_type":"code","source":"class PathAggregationBlock(nn.Module):\n    def __init__(self, c_in) -> None:\n        super(PathAggregationBlock, self).__init__()\n\n        self.conv1 = Conv(c_in, c_in, 3, 2)\n        self.conv2 = Conv(2 * c_in, 2 * c_in, 3)\n\n    def forward(self, x):\n        [x1, x2] = x\n        x1 = self.conv1(x1)\n        concat = torch.cat([x1, x2], 1)\n        return self.conv2(concat)","metadata":{"id":"RUV3i5JJCdf-","trusted":true,"execution":{"iopub.status.busy":"2025-08-27T20:34:01.305700Z","iopub.execute_input":"2025-08-27T20:34:01.305913Z","iopub.status.idle":"2025-08-27T20:34:01.319428Z","shell.execute_reply.started":"2025-08-27T20:34:01.305898Z","shell.execute_reply":"2025-08-27T20:34:01.318895Z"}},"outputs":[],"execution_count":11},{"cell_type":"markdown","source":"### Path aggregation network","metadata":{"id":"QUArz0BdFqJ0"}},{"cell_type":"code","source":"class PathAggregationNetwork(nn.Module):\n    def __init__(self, c_in) -> None:\n        super(PathAggregationNetwork, self).__init__()\n\n        self.n3 = Conv(c_in[0], c_in[0], 1)\n        self.layers = nn.ModuleList([PathAggregationBlock(n_in) for n_in in c_in[1:]])\n\n    def forward(self, x):\n        x = x[::-1]\n        output = [self.n3(x[0])]\n\n        for layer, xi in zip(self.layers, x[1:]):\n            output.append(layer([output[-1], xi]))\n\n        return output","metadata":{"id":"ztzv753iCdf-","trusted":true,"execution":{"iopub.status.busy":"2025-08-27T20:34:01.320118Z","iopub.execute_input":"2025-08-27T20:34:01.320333Z","iopub.status.idle":"2025-08-27T20:34:01.334296Z","shell.execute_reply.started":"2025-08-27T20:34:01.320313Z","shell.execute_reply":"2025-08-27T20:34:01.333690Z"}},"outputs":[],"execution_count":12},{"cell_type":"markdown","source":"### Detect head","metadata":{"id":"jDUHRDgXFsua"}},{"cell_type":"code","source":"class DetectHead(nn.Module):\n    def __init__(self, nc, anchors,\n               c_in=[128, 128, 256], c_h=[128, 256, 512]) -> None:\n        super(DetectHead, self).__init__()\n\n        self.pan = PathAggregationNetwork(c_in)\n        self.stride = torch.tensor([8, 16, 32])\n        self.nc = nc\n        self.no = nc + 5\n        self.nl = len(anchors)\n        self.na = len(anchors[0])\n        self.grid = [torch.zeros(1)] * self.nl\n        self.register_buffer('anchor_grid', anchors.float().view(self.nl, 1, -1, 1, 1, 2))\n        self.detectors = nn.ModuleList(\n            [nn.Conv2d(n_h, self.no * self.na, 1) for n_h in c_h]\n        )\n\n    def forward(self, x):\n        x = self.pan(x)\n\n        for i in range(self.nl):\n            x[i] = self.detectors[i](x[i])\n            bs, _, ny, nx = x[i].shape\n\n            if self.grid[i].shape[2:4] != x[i].shape[2:4]:\n                self.grid[i] = self.make_grid(nx, ny).to(x[i].device)\n\n            x[i] = x[i].view(bs, self.na, self.no, ny, nx).permute(0, 1, 3, 4, 2).contiguous()\n\n            x[i][..., 0:2] = (x[i][..., 0:2].sigmoid() + self.grid[i]) * self.stride[i]\n            x[i][..., 2:4] = (x[i][..., 2:4].sigmoid() ** 2) * self.anchor_grid[i].to(x[i].device)\n\n            if not self.training:\n                x[i][..., 4:] = x[i][..., 4:].sigmoid()\n\n            x[i] = x[i].view(bs, -1, self.no)\n\n        return torch.cat(x, dim=1)\n\n    @staticmethod\n    def make_grid(nx, ny):\n        yv, xv = torch.meshgrid([torch.arange(ny), torch.arange(nx)])\n        return torch.stack((xv, yv), 2).view((1, 1, ny, nx, 2)).float()","metadata":{"id":"F6wcsiXMCdf-","trusted":true,"execution":{"iopub.status.busy":"2025-08-27T20:34:01.334949Z","iopub.execute_input":"2025-08-27T20:34:01.335183Z","iopub.status.idle":"2025-08-27T20:34:01.351036Z","shell.execute_reply.started":"2025-08-27T20:34:01.335163Z","shell.execute_reply":"2025-08-27T20:34:01.350313Z"}},"outputs":[],"execution_count":13},{"cell_type":"markdown","source":"## Full implementation","metadata":{"id":"MGti2OJdCdf_"}},{"cell_type":"code","source":"DEFAULT_ANCHORS = torch.tensor([\n    [(12, 16), (19, 36), (40, 28)],\n    [(36, 75), (76, 55), (72, 146)],\n    [(142, 110), (192, 243), (459, 401)]\n])\n\nclass YOLOP(nn.Module):\n    def __init__(self, nc=10, anchors=DEFAULT_ANCHORS):\n        super(YOLOP, self).__init__()\n\n        self.backbone = Backbone()\n        self.neck = Neck()\n        self.drivableAreaHead = DrivableAreaSegmentHead(512, [256, 128, 64, 32, 1])\n        self.laneHead = LaneSegmentHead(128, [64, 32, 1])\n        self.detectHead = DetectHead(nc, anchors)\n\n    def forward(self, x):\n        x = self.backbone(x)\n        drivable = self.drivableAreaHead(x[-1])\n        x = self.neck(x)\n        lanes = self.laneHead(x[-1])\n        boxes = self.detectHead(x)\n\n        return drivable, lanes, boxes","metadata":{"id":"GsnTXbWlCdf_","trusted":true,"execution":{"iopub.status.busy":"2025-08-27T20:34:01.351648Z","iopub.execute_input":"2025-08-27T20:34:01.351869Z","iopub.status.idle":"2025-08-27T20:34:01.370426Z","shell.execute_reply.started":"2025-08-27T20:34:01.351854Z","shell.execute_reply":"2025-08-27T20:34:01.369912Z"}},"outputs":[],"execution_count":14},{"cell_type":"code","source":"model = YOLOP()\nmodel.eval()\nx = torch.randint(0, 255, (1, 3, 640, 640)).float()\n\np_drv, p_lanes, p_boxes = model(x)\n#print(p_drv.shape)\n#print(p_lanes.shape)\n#print(p_boxes.shape)\nprint(p_boxes[..., 0:4].min(), p_boxes[..., 0:4].max())\nprint(p_boxes[..., 4].min(), p_boxes[..., 4].max())\nprint(p_boxes[..., 5:].min(), p_boxes[..., 5:].max())\n\ndel model, x, p_drv, p_lanes, p_boxes\ntorch.cuda.empty_cache()\ngc.collect()","metadata":{"id":"ycpup8GyCdf_","trusted":true,"outputId":"fab1ee0c-b0f0-4179-daf1-65dcb82b4cc7","colab":{"base_uri":"https://localhost:8080/"},"execution":{"iopub.status.busy":"2025-08-27T22:13:33.014865Z","iopub.execute_input":"2025-08-27T22:13:33.015620Z","iopub.status.idle":"2025-08-27T22:13:33.883778Z","shell.execute_reply.started":"2025-08-27T22:13:33.015588Z","shell.execute_reply":"2025-08-27T22:13:33.883015Z"}},"outputs":[{"name":"stdout","text":"tensor(3.1008, grad_fn=<MinBackward1>) tensor(636.1478, grad_fn=<MaxBackward1>)\ntensor(0.4899, grad_fn=<MinBackward1>) tensor(0.5146, grad_fn=<MaxBackward1>)\ntensor(0.4783, grad_fn=<MinBackward1>) tensor(0.5202, grad_fn=<MaxBackward1>)\n","output_type":"stream"},{"execution_count":87,"output_type":"execute_result","data":{"text/plain":"0"},"metadata":{}}],"execution_count":87},{"cell_type":"markdown","source":"# Dataset","metadata":{"id":"zVhAr5ruCdf6"}},{"cell_type":"markdown","source":"## Download dataset","metadata":{"id":"zIIYhU38F3ku"}},{"cell_type":"code","source":"# import kagglehub\n\n# # Download latest version\n# DATASET_PATH = kagglehub.dataset_download(\"alesssaulea/bdd100k\")\n# DATASET_PATH","metadata":{"id":"8OkQW1VtIPqQ","trusted":true,"outputId":"3deb9f55-53ae-4f73-9b3b-30297b28e4ae","colab":{"base_uri":"https://localhost:8080/","height":36},"execution":{"iopub.status.busy":"2025-08-27T20:34:02.883409Z","iopub.execute_input":"2025-08-27T20:34:02.883698Z","iopub.status.idle":"2025-08-27T20:34:02.887041Z","shell.execute_reply.started":"2025-08-27T20:34:02.883681Z","shell.execute_reply":"2025-08-27T20:34:02.886325Z"}},"outputs":[],"execution_count":16},{"cell_type":"code","source":"DATASET_PATH = '/kaggle/input/bdd100k'","metadata":{"id":"iqk1XDCYO3wW","trusted":true,"execution":{"iopub.status.busy":"2025-08-27T20:34:02.887807Z","iopub.execute_input":"2025-08-27T20:34:02.888001Z","iopub.status.idle":"2025-08-27T20:34:02.902896Z","shell.execute_reply.started":"2025-08-27T20:34:02.887987Z","shell.execute_reply":"2025-08-27T20:34:02.902299Z"}},"outputs":[],"execution_count":17},{"cell_type":"markdown","source":"## Paths","metadata":{"id":"h7JnbMCeCdf7"}},{"cell_type":"code","source":"IMAGE_TRAIN_PATH = DATASET_PATH + '/images/100k/train'\nIMAGE_VAL_PATH = DATASET_PATH + '/images/100k/val'\n\nDET_TRAIN_PATH = DATASET_PATH + '/labels/det_20/train'\nDET_VAL_PATH = DATASET_PATH + '/labels/det_20/val'\n\nDRIVABLE_TRAIN_PATH = DATASET_PATH + '/labels/drivable/colormaps/train'\nDRIVABLE_VAL_PATH = DATASET_PATH + '/labels/drivable/colormaps/val'\n\nLANE_TRAIN_PATH = DATASET_PATH + '/labels/lane/colormaps/train'\nLANE_VAL_PATH = DATASET_PATH + '/labels/lane/colormaps/val'","metadata":{"id":"u1yvXYtXCdf7","trusted":true,"execution":{"iopub.status.busy":"2025-08-27T20:34:02.903607Z","iopub.execute_input":"2025-08-27T20:34:02.903882Z","iopub.status.idle":"2025-08-27T20:34:02.917557Z","shell.execute_reply.started":"2025-08-27T20:34:02.903864Z","shell.execute_reply":"2025-08-27T20:34:02.916984Z"}},"outputs":[],"execution_count":18},{"cell_type":"markdown","source":"## Utils","metadata":{"id":"rp2fRNdRCdf7"}},{"cell_type":"code","source":"CATEGORY_TO_INT = {\n  \"bicycle\": 0,\n  \"bus\": 1,\n  \"car\": 2,\n  \"motorcycle\": 3,\n  \"person\": 4,\n  \"pedestrian\": 4,\n  \"rider\": 5,\n  \"traffic light\": 6,\n  \"traffic sign\": 7,\n  \"train\": 8,\n  \"truck\": 9,\n  \"trailer\": 9\n}","metadata":{"id":"EmAi4m5tCdf7","trusted":true,"execution":{"iopub.status.busy":"2025-08-27T20:34:02.918383Z","iopub.execute_input":"2025-08-27T20:34:02.918665Z","iopub.status.idle":"2025-08-27T20:34:02.933127Z","shell.execute_reply.started":"2025-08-27T20:34:02.918641Z","shell.execute_reply":"2025-08-27T20:34:02.932554Z"}},"outputs":[],"execution_count":19},{"cell_type":"markdown","source":"## Dataset class","metadata":{"id":"dplfIIFDCdf8"}},{"cell_type":"code","source":"class BDD100K(Dataset):\n    def __init__(self, img_dir, drv_dir, lane_dir, det_dir, out_s, n=0, train=True):\n        self.img_dir = img_dir\n        self.drv_dir = drv_dir\n        self.lane_dir = lane_dir\n        self.det_dir = det_dir\n        self.out_s = out_s\n        self.transform = ToTensorV2()\n        self.train = train\n\n        img_list: list[str] = os.listdir(self.img_dir)\n        if n > 0:\n            img_list = random.sample(img_list, n)\n\n        self.images = []\n        for file in tqdm(img_list, total=len(img_list)):\n            self.images.append(self.load_image(file))\n\n        if self.train:\n            self.anchors = self.generate_anchors()\n\n    def load_image(self, file):\n        img_path = self.img_dir + '/' + file\n        det_path = self.det_dir + '/' + file.replace('.jpg', '.json')\n        drv_path = self.drv_dir + '/' + file.replace('.jpg', '.png')\n        lane_path = self.lane_dir + '/' + file.replace('.jpg', '.png')\n\n        img = cv2.imread(img_path)\n        h, w, _ = img.shape\n        img = cv2.resize(img, self.out_s)\n\n        drv = cv2.imread(drv_path, cv2.IMREAD_GRAYSCALE)\n        drv = cv2.resize(drv, self.out_s)\n        drv = (drv > 0).astype(np.float32)\n\n        lanes = cv2.imread(lane_path, cv2.IMREAD_GRAYSCALE)\n        lanes = cv2.resize(lanes, self.out_s)\n        lanes = (lanes > 0).astype(np.float32)\n\n        try:\n            with open(det_path) as f:\n                obj = json.load(f)\n                labels = obj['labels'] if 'labels' in obj else []\n        except:\n            labels = []\n\n        boxes = []\n        sw, sh = self.out_s\n        ratio_x, ratio_y = sw / w, sh / h\n\n        for lbl in labels:\n            if lbl['category'] in CATEGORY_TO_INT:\n                cat = CATEGORY_TO_INT[lbl['category']]\n                x1 = lbl['box2d']['x1'] * ratio_x\n                y1 = lbl['box2d']['y1'] * ratio_y\n                x2 = lbl['box2d']['x2'] * ratio_x\n                y2 = lbl['box2d']['y2'] * ratio_y\n\n                assert 0 <= x1 <= sw\n                assert 0 <= y1 <= sh\n                assert 0 <= x2 <= sw\n                assert 0 <= y2 <= sh\n\n                xc = (x1 + x2) / 2\n                yc = (y1 + y2) / 2\n                wb = abs(x1 - x2)\n                hb = abs(y1 - y2)\n\n                assert wb > 0\n                assert hb > 0\n\n                boxes.append((xc, yc, wb, hb, cat))\n\n        transf = self.transform(image=img, masks=[drv, lanes])\n        img = transf['image'].float()\n        drv, lanes = transf['masks']\n\n        return [img, drv, lanes, torch.tensor(boxes)]\n\n    def generate_anchors(self):\n        boxes = [[wb, hb] for _, _, _, lbls in self.images for _, _, wb, hb, _ in lbls]\n        kmeans = KMeans(n_clusters=9, random_state=0)\n        kmeans.fit(boxes)\n        anchors = kmeans.cluster_centers_\n        anchors = anchors[np.argsort(anchors[:, 0] * anchors[:, 1])]\n        return torch.tensor(anchors).reshape((3, 3, 2)).float()\n\n    def __getitem__(self, index):\n        return self.images[index]\n\n    def __len__(self):\n        return len(self.images)","metadata":{"id":"7FfRETUFCdf8","trusted":true,"execution":{"iopub.status.busy":"2025-08-27T20:34:02.933747Z","iopub.execute_input":"2025-08-27T20:34:02.933913Z","iopub.status.idle":"2025-08-27T20:34:02.953392Z","shell.execute_reply.started":"2025-08-27T20:34:02.933901Z","shell.execute_reply":"2025-08-27T20:34:02.952822Z"}},"outputs":[],"execution_count":20},{"cell_type":"markdown","source":"# Training","metadata":{"id":"zw1XC7AlCdf_"}},{"cell_type":"markdown","source":"## Setup","metadata":{"id":"-8Pqlp8pCdf_"}},{"cell_type":"code","source":"device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\ndevice","metadata":{"id":"4uMGCvn0Cdf_","trusted":true,"outputId":"672da5f5-0fb4-455a-d5bd-009b63451a71","colab":{"base_uri":"https://localhost:8080/"},"execution":{"iopub.status.busy":"2025-08-27T20:34:02.954110Z","iopub.execute_input":"2025-08-27T20:34:02.954289Z","iopub.status.idle":"2025-08-27T20:34:03.032852Z","shell.execute_reply.started":"2025-08-27T20:34:02.954264Z","shell.execute_reply":"2025-08-27T20:34:03.032147Z"}},"outputs":[{"execution_count":21,"output_type":"execute_result","data":{"text/plain":"device(type='cuda')"},"metadata":{}}],"execution_count":21},{"cell_type":"code","source":"dataset = BDD100K(IMAGE_TRAIN_PATH, DRIVABLE_TRAIN_PATH, LANE_TRAIN_PATH, DET_TRAIN_PATH, (640, 640), n=300)","metadata":{"id":"1rsz1183CdgA","trusted":true,"outputId":"3bf4cb0e-b28e-4ece-b2e3-485c491f50ab","colab":{"base_uri":"https://localhost:8080/"},"execution":{"iopub.status.busy":"2025-08-27T20:34:03.036196Z","iopub.execute_input":"2025-08-27T20:34:03.036369Z","iopub.status.idle":"2025-08-27T20:34:17.298920Z","shell.execute_reply.started":"2025-08-27T20:34:03.036357Z","shell.execute_reply":"2025-08-27T20:34:17.297991Z"}},"outputs":[{"name":"stderr","text":"100%|██████████| 300/300 [00:12<00:00, 23.70it/s]\n/usr/local/lib/python3.11/dist-packages/sklearn/cluster/_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n  warnings.warn(\n","output_type":"stream"}],"execution_count":22},{"cell_type":"code","source":"def collate_fn(batch):\n    imgs, drvs, lanes, lbls = zip(*batch)\n    return list(imgs), list(drvs), list(lanes), list(lbls)","metadata":{"id":"-U8WPd6mCdgA","trusted":true,"execution":{"iopub.status.busy":"2025-08-27T20:34:17.299890Z","iopub.execute_input":"2025-08-27T20:34:17.300112Z","iopub.status.idle":"2025-08-27T20:34:17.304680Z","shell.execute_reply.started":"2025-08-27T20:34:17.300094Z","shell.execute_reply":"2025-08-27T20:34:17.303823Z"}},"outputs":[],"execution_count":23},{"cell_type":"code","source":"data_loader = DataLoader(dataset, batch_size=8, shuffle=True, collate_fn=collate_fn)","metadata":{"id":"Mul9FgWmCdgA","trusted":true,"execution":{"iopub.status.busy":"2025-08-27T20:34:17.305452Z","iopub.execute_input":"2025-08-27T20:34:17.305751Z","iopub.status.idle":"2025-08-27T20:34:17.323713Z","shell.execute_reply.started":"2025-08-27T20:34:17.305727Z","shell.execute_reply":"2025-08-27T20:34:17.323029Z"}},"outputs":[],"execution_count":24},{"cell_type":"markdown","source":"## Loss function","metadata":{"id":"vqbdGvWHCdgA"}},{"cell_type":"code","source":"def center_regions(boxes, radius=2.5):\n    center_w = boxes[:, 2] / radius\n    center_h = boxes[:, 3] / radius\n\n    cx1 = boxes[:, 0] - center_w\n    cy1 = boxes[:, 1] - center_h\n    cx2 = boxes[:, 0] + center_w\n    cy2 = boxes[:, 1] + center_h\n\n    return torch.cat([cx1.unsqueeze(1), cy1.unsqueeze(1), cx2.unsqueeze(1), cy2.unsqueeze(1)], dim=1)","metadata":{"id":"VLaA7qxxJ1Sy","trusted":true,"execution":{"iopub.status.busy":"2025-08-27T20:34:17.324551Z","iopub.execute_input":"2025-08-27T20:34:17.324850Z","iopub.status.idle":"2025-08-27T20:34:17.340843Z","shell.execute_reply.started":"2025-08-27T20:34:17.324824Z","shell.execute_reply":"2025-08-27T20:34:17.340301Z"}},"outputs":[],"execution_count":25},{"cell_type":"code","source":"def filter_pred_in_center_region(p_boxes, c_regions):\n    gt_x1 = c_regions[:, 0].unsqueeze(1)\n    gt_y1 = c_regions[:, 1].unsqueeze(1)\n    gt_x2 = c_regions[:, 2].unsqueeze(1)\n    gt_y2 = c_regions[:, 3].unsqueeze(1)\n\n    px = p_boxes[:, 0].unsqueeze(0)\n    py = p_boxes[:, 1].unsqueeze(0)\n\n    in_x = (px >= gt_x1) & (px <= gt_x2)\n    in_y = (py >= gt_y1) & (py <= gt_y2)\n\n    return in_x & in_y","metadata":{"id":"kZrwwYE0bT5M","trusted":true,"execution":{"iopub.status.busy":"2025-08-27T20:34:17.341540Z","iopub.execute_input":"2025-08-27T20:34:17.341762Z","iopub.status.idle":"2025-08-27T20:34:17.356899Z","shell.execute_reply.started":"2025-08-27T20:34:17.341744Z","shell.execute_reply":"2025-08-27T20:34:17.356216Z"}},"outputs":[],"execution_count":26},{"cell_type":"code","source":"def compute_iou(boxes1, boxes2):\n    boxes1_xyxy = ops.box_convert(boxes1, 'cxcywh', 'xyxy')\n    boxes2_xyxy = ops.box_convert(boxes2, 'cxcywh', 'xyxy')\n    return ops.box_iou(boxes1_xyxy, boxes2_xyxy)","metadata":{"id":"G-RR-45Wb-6w","trusted":true,"execution":{"iopub.status.busy":"2025-08-27T20:34:17.357504Z","iopub.execute_input":"2025-08-27T20:34:17.357684Z","iopub.status.idle":"2025-08-27T20:34:17.374951Z","shell.execute_reply.started":"2025-08-27T20:34:17.357670Z","shell.execute_reply":"2025-08-27T20:34:17.374489Z"}},"outputs":[],"execution_count":27},{"cell_type":"code","source":"def simota(p_boxes, gt_boxes, l_iou=6.0, l_cls=1.0):\n    num_pred = len(p_boxes)\n    num_gt = len(gt_boxes)\n    nc = p_boxes.size(-1) - 5\n\n    c_regions = center_regions(gt_boxes)\n    is_in_center = filter_pred_in_center_region(p_boxes, c_regions)\n\n    ious = compute_iou(gt_boxes[:, :4], p_boxes[:, :4])\n    iou_cost = 1 - ious\n\n    gt_cls = F.one_hot(gt_boxes[:, 4].long(), nc).unsqueeze(1).repeat(1, num_pred, 1).float()\n    pred_cls = p_boxes[:, 5:].unsqueeze(0).repeat(num_gt, 1, 1)\n    cls_cost = F.binary_cross_entropy_with_logits(pred_cls, gt_cls, reduction='none').sum(-1)\n\n    cost = l_iou * iou_cost + l_cls * cls_cost\n    cost[~is_in_center] = torch.inf\n\n    matched_gt_indices = []\n    matched_pred_indices = []\n\n    for i in range(num_gt):\n        iou_row = ious[i]\n        top_k = min(10, iou_row.size(0))\n        topk_ious, _ = torch.topk(iou_row, top_k)\n\n        dynamic_k = max(topk_ious.sum().int().item(), 1)\n\n        valid_cost = torch.where(torch.isfinite(cost[i]), cost[i], torch.full_like(cost[i], 1e6))\n        _, topk_cost_idx = torch.topk(valid_cost, dynamic_k, largest=False)\n\n        matched_pred_indices.append(topk_cost_idx)\n        matched_gt_indices.append(torch.full_like(topk_cost_idx, i))\n\n    matched_pred_indices = torch.cat(matched_pred_indices)\n    matched_gt_indices = torch.cat(matched_gt_indices)\n\n    unique_pred_indices = matched_pred_indices.unique()\n    final_gt_indices = torch.full_like(unique_pred_indices, -1)\n\n    for i, pred_idx in enumerate(unique_pred_indices):\n        mask = matched_pred_indices == pred_idx\n        costs = cost[matched_gt_indices[mask], matched_pred_indices[mask]]\n        min_cost_idx = torch.argmin(costs)\n        final_gt_indices[i] = matched_gt_indices[mask][min_cost_idx]\n\n    matched_preds = p_boxes[unique_pred_indices]\n    matched_gts = gt_boxes[final_gt_indices]\n\n    return unique_pred_indices, final_gt_indices","metadata":{"id":"qxz2YH6WL0GX","trusted":true,"execution":{"iopub.status.busy":"2025-08-27T21:19:34.928971Z","iopub.execute_input":"2025-08-27T21:19:34.929257Z","iopub.status.idle":"2025-08-27T21:19:34.937638Z","shell.execute_reply.started":"2025-08-27T21:19:34.929237Z","shell.execute_reply":"2025-08-27T21:19:34.936894Z"}},"outputs":[],"execution_count":51},{"cell_type":"code","source":"def detection_loss(p_boxes, gt_boxes, l_obj=0.5, l_cls=1.0, l_reg=5.0):\n    b = len(p_boxes)\n    reg_loss = torch.tensor(0., device=p_boxes.device)\n    obj_loss = torch.tensor(0., device=p_boxes.device)\n    cls_loss = torch.tensor(0., device=p_boxes.device)\n\n    for bi in range(b):\n        p_boxes_i = p_boxes[bi]\n        gt_boxes_i = gt_boxes[bi]\n\n        if len(gt_boxes_i) == 0:\n            continue\n\n        nc = p_boxes_i.size(-1) - 5\n\n        unique_pred_indices, final_gt_indices = simota(p_boxes_i, gt_boxes_i)\n        num_pos = len(unique_pred_indices)\n\n        matched_preds = p_boxes_i[unique_pred_indices]\n        matched_gts = gt_boxes_i[final_gt_indices]\n\n        reg_loss += (1.0 - compute_iou(matched_preds[:, :4], matched_gts[:, :4]).diag()).sum() / num_pos\n\n        obj_target = torch.zeros_like(p_boxes_i[:, 4], device=p_boxes.device)\n        obj_target[unique_pred_indices] = 1.0\n        obj_loss += ops.sigmoid_focal_loss(p_boxes_i[:, 4], obj_target, reduction='sum') / num_pos\n\n        gt_cls = F.one_hot(matched_gts[:, 4].long(), nc).float().to(p_boxes.device)\n        cls_loss += ops.sigmoid_focal_loss(matched_preds[:, 5:], gt_cls, reduction='sum') / num_pos\n\n    return (l_obj * obj_loss + l_cls * cls_loss + l_reg * reg_loss) / b\n\ndef compute_loss(gt_drv, gt_lanes, gt_boxes, p_drv, p_lanes, p_boxes, l_drv=0.2, l_lanes=0.2, l_det=0.75):\n    det_loss = detection_loss(p_boxes, gt_boxes)\n    #drv_loss = F.binary_cross_entropy_with_logits(p_drv.squeeze(1), gt_drv, reduction='mean')\n    #lanes_loss = ops.sigmoid_focal_loss(p_lanes.squeeze(1), gt_lanes, reduction='mean')\n\n    #return l_det * det_loss + l_drv * drv_loss + l_lanes * lanes_loss\n    return det_loss","metadata":{"id":"g3SlKAGlCdgA","trusted":true,"execution":{"iopub.status.busy":"2025-08-27T22:08:48.797038Z","iopub.execute_input":"2025-08-27T22:08:48.797287Z","iopub.status.idle":"2025-08-27T22:08:48.804800Z","shell.execute_reply.started":"2025-08-27T22:08:48.797271Z","shell.execute_reply":"2025-08-27T22:08:48.804050Z"}},"outputs":[],"execution_count":82},{"cell_type":"markdown","source":"## Metrics","metadata":{"id":"tA-U9Ga6CaTb"}},{"cell_type":"code","source":"def compute_recall(pred_batch, gt_batch, iou_th=0.5, conf_th=0.3):\n    total_tp, total_fn = 0, 0\n\n    for i in range(len(pred_batch)):\n        pred = pred_batch[i]\n        gt = gt_batch[i]\n\n        if gt.numel() == 0:\n            continue\n\n        if pred.numel() == 0:\n            total_fn += len(gt)\n            continue\n\n        pred = pred[pred[:, 4] > conf_th]\n\n        if pred.numel() == 0:\n            total_fn += len(gt)\n            continue\n\n        p_boxes = pred[:, :4]\n        p_scores = pred[:, 4]\n        p_cls = pred[:, 5:].argmax(dim=-1)\n\n        gt_boxes = gt[:, :4]\n        gt_cls = gt[:, 4]\n\n        ious = compute_iou(p_boxes, gt_boxes)\n\n        matched_gt = torch.zeros(len(gt_boxes), dtype=torch.bool)\n        tp = 0\n\n        for j in range(len(pred)):\n            max_iou, gt_idx = ious[j].max(0)\n\n            if max_iou >= iou_th and not matched_gt[gt_idx.item()] and p_cls[j] == gt_cls[gt_idx]:\n                tp += 1\n                matched_gt[gt_idx.item()] = True\n\n        fn = len(gt_boxes) - matched_gt.sum()\n        total_tp += tp\n        total_fn += fn\n\n    return total_tp / (total_tp + total_fn) if total_tp + total_fn > 0 else 0","metadata":{"id":"GWUgbWB0D6eQ","trusted":true,"execution":{"iopub.status.busy":"2025-08-27T21:47:01.299597Z","iopub.execute_input":"2025-08-27T21:47:01.299868Z","iopub.status.idle":"2025-08-27T21:47:01.306590Z","shell.execute_reply.started":"2025-08-27T21:47:01.299847Z","shell.execute_reply":"2025-08-27T21:47:01.305772Z"}},"outputs":[],"execution_count":74},{"cell_type":"markdown","source":"## Training loop","metadata":{"id":"2lgXd21QCdgK"}},{"cell_type":"code","source":"torch.cuda.empty_cache()\ngc.collect()","metadata":{"id":"Hjw2jSR1MHLE","trusted":true,"outputId":"250a4d66-464a-4d2f-fafd-a0b2e0059c7e","colab":{"base_uri":"https://localhost:8080/"},"execution":{"iopub.status.busy":"2025-08-27T22:19:26.117775Z","iopub.execute_input":"2025-08-27T22:19:26.118092Z","iopub.status.idle":"2025-08-27T22:19:26.310658Z","shell.execute_reply.started":"2025-08-27T22:19:26.118071Z","shell.execute_reply":"2025-08-27T22:19:26.309703Z"}},"outputs":[{"execution_count":88,"output_type":"execute_result","data":{"text/plain":"0"},"metadata":{}}],"execution_count":88},{"cell_type":"code","source":"model = YOLOP(anchors=dataset.anchors).to(device)\n\noptimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.937, weight_decay=0.005)\nscheduler = optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer, 10, 2, 1e-5)\n\nepochs = 100\npatience, counter = 5, 0\nbest_loss = float('inf')\n\nfor epoch in range(epochs):\n    model.train()\n    epoch_loss = 0\n\n    for images, gt_drv, gt_lanes, gt_boxes in tqdm(data_loader):\n        images = torch.stack(images).float().to(device)\n        gt_drv = torch.stack(gt_drv).to(device)\n        gt_lanes = torch.stack(gt_lanes).to(device)\n        gt_boxes = [boxes.to(device) for boxes in gt_boxes]\n\n        #forward pass\n        p_drv, p_lanes, p_boxes = model(images)\n\n        assert not torch.any(torch.isnan(p_boxes))\n        assert torch.any(p_boxes[..., :4] >= 0)\n        assert torch.any(p_boxes[..., :4] <= 640)\n\n        #loss calculation\n        loss = compute_loss(gt_drv, gt_lanes, gt_boxes, p_drv, p_lanes, p_boxes)\n\n        #Backpropagation\n        optimizer.zero_grad()\n        loss.backward()\n        optimizer.step()\n\n        epoch_loss += loss.item()\n\n    if epoch_loss < best_loss:\n        best_loss = epoch_loss\n        counter = 0\n        torch.save(model.state_dict(), \"yolop_v2_mini.pth\")\n    else:\n        counter += 1\n\n    model.eval()\n    recall_score = 0\n\n    with torch.no_grad():\n        for images, gt_drv, gt_lanes, gt_boxes in tqdm(data_loader):\n            images = torch.stack(images).float().to(device)\n            gt_drv = torch.stack(gt_drv).to(device)\n            gt_lanes = torch.stack(gt_lanes).to(device)\n            gt_boxes = [boxes.to(device) for boxes in gt_boxes]\n\n            #forward pass\n            p_drv, p_lanes, p_boxes = model(images)\n\n            recall_score += compute_recall(p_boxes, gt_boxes)\n\n            del p_drv, p_lanes, p_boxes\n\n    recall_score /= len(data_loader)\n\n    print(f\"Epoch {epoch+1}/{epochs}, Loss: {epoch_loss:.4f}, recall: {recall_score:.4f}\")\n\n    if counter >= patience:\n        print('Training stopped early')\n        break\n\ndel model, p_drv, p_lanes, p_boxes, loss\ntorch.cuda.empty_cache()\ngc.collect()","metadata":{"id":"q7pl53WwCdgK","trusted":true,"outputId":"47d1e116-5e8a-419b-9a4a-963c90a1c779","colab":{"base_uri":"https://localhost:8080/"},"execution":{"iopub.status.busy":"2025-08-27T22:08:56.558668Z","iopub.execute_input":"2025-08-27T22:08:56.558963Z","iopub.status.idle":"2025-08-27T22:10:19.029432Z","shell.execute_reply.started":"2025-08-27T22:08:56.558945Z","shell.execute_reply":"2025-08-27T22:10:19.028470Z"}},"outputs":[{"name":"stderr","text":"100%|██████████| 38/38 [00:15<00:00,  2.41it/s]\n100%|██████████| 38/38 [00:03<00:00, 10.32it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 1/100, Loss: 273.3020, recall: 0.0000\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 38/38 [00:15<00:00,  2.39it/s]\n100%|██████████| 38/38 [00:03<00:00, 10.56it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 2/100, Loss: 164.9824, recall: 0.0000\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 38/38 [00:15<00:00,  2.39it/s]\n100%|██████████| 38/38 [00:03<00:00, 10.47it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 3/100, Loss: 138.5823, recall: 0.0000\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 38/38 [00:15<00:00,  2.38it/s]\n100%|██████████| 38/38 [00:03<00:00, 10.60it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 4/100, Loss: 135.0162, recall: 0.0000\n","output_type":"stream"},{"name":"stderr","text":" 18%|█▊        | 7/38 [00:03<00:14,  2.15it/s]\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_35/1537699516.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m         \u001b[0;31m#loss calculation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompute_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgt_drv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgt_lanes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgt_boxes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp_drv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp_lanes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp_boxes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m         \u001b[0;31m#Backpropagation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/tmp/ipykernel_35/275161135.py\u001b[0m in \u001b[0;36mcompute_loss\u001b[0;34m(gt_drv, gt_lanes, gt_boxes, p_drv, p_lanes, p_boxes, l_drv, l_lanes, l_det)\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mcompute_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgt_drv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgt_lanes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgt_boxes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp_drv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp_lanes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp_boxes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ml_drv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ml_lanes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ml_det\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.75\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m     \u001b[0mdet_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdetection_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp_boxes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgt_boxes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     35\u001b[0m     \u001b[0;31m#drv_loss = F.binary_cross_entropy_with_logits(p_drv.squeeze(1), gt_drv, reduction='mean')\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m     \u001b[0;31m#lanes_loss = ops.sigmoid_focal_loss(p_lanes.squeeze(1), gt_lanes, reduction='mean')\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/tmp/ipykernel_35/275161135.py\u001b[0m in \u001b[0;36mdetection_loss\u001b[0;34m(p_boxes, gt_boxes, l_obj, l_cls, l_reg)\u001b[0m\n\u001b[1;32m     20\u001b[0m         \u001b[0mmatched_gts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgt_boxes_i\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfinal_gt_indices\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m         \u001b[0mreg_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1.0\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mcompute_iou\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmatched_preds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmatched_gts\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdiag\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mnum_pos\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m         \u001b[0mobj_target\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp_boxes_i\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mp_boxes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/tmp/ipykernel_35/1867608122.py\u001b[0m in \u001b[0;36mcompute_iou\u001b[0;34m(boxes1, boxes2)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mcompute_iou\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mboxes1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mboxes2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mboxes1_xyxy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbox_convert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mboxes1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'cxcywh'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'xyxy'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mboxes2_xyxy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbox_convert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mboxes2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'cxcywh'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'xyxy'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbox_iou\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mboxes1_xyxy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mboxes2_xyxy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torchvision/ops/boxes.py\u001b[0m in \u001b[0;36mbox_convert\u001b[0;34m(boxes, in_fmt, out_fmt)\u001b[0m\n\u001b[1;32m    229\u001b[0m             \u001b[0mboxes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_box_xywh_to_xyxy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mboxes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    230\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0min_fmt\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"cxcywh\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 231\u001b[0;31m             \u001b[0mboxes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_box_cxcywh_to_xyxy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mboxes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    232\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mboxes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    233\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torchvision/ops/_box_convert.py\u001b[0m in \u001b[0;36m_box_cxcywh_to_xyxy\u001b[0;34m(boxes)\u001b[0m\n\u001b[1;32m     15\u001b[0m     \"\"\"\n\u001b[1;32m     16\u001b[0m     \u001b[0;31m# We need to change all 4 of them so some temporary variable is needed.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m     \u001b[0mcx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mboxes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munbind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m     \u001b[0mx1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcx\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m0.5\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mw\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0my1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcy\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m0.5\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mh\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "],"ename":"KeyboardInterrupt","evalue":"","output_type":"error"}],"execution_count":84},{"cell_type":"code","source":"model = YOLOP(anchors=dataset.anchors).to(device)\n\n# pick first batch item\nimages, _, _, gt_boxes_batch = next(iter(data_loader))\nimages = torch.stack(images).float().to(device)\ngt_boxes_batch = [b.to(device) for b in gt_boxes_batch]\n\nmodel.eval()\nwith torch.no_grad():\n    p_drv, p_lanes, p_boxes_batch = model(images)\n\n# choose first image in batch\ni = 0\npred = p_boxes_batch[i].detach().cpu()   # shape [N, 5+nc]\ngt   = gt_boxes_batch[i].detach().cpu()  # shape [M, 5]\n\nprint(\"num_preds, num_gt:\", pred.shape[0], gt.shape[0])\nprint(\"pred (cx,cy,w,h,obj) sample rows (first 10):\")\nprint(pred[:10, :6])\nprint(\"gt (cx,cy,w,h,cls) sample rows (first 10):\")\nprint(gt[:10])\n\n# are preds logits or probs?\nprint(\"pred obj min/max:\", pred[:,4].min().item(), pred[:,4].max().item())\nprint(\"pred class logits min/max:\", pred[:,5:].min().item(), pred[:,5:].max().item())\n\n# convert to xyxy for IoU (both are in cxcywh pixels per your code)\npred_xyxy = ops.box_convert(pred[:, :4], in_fmt='cxcywh', out_fmt='xyxy')  # [N,4]\ngt_xyxy   = ops.box_convert(gt[:, :4],   in_fmt='cxcywh', out_fmt='xyxy')  # [M,4]\n\nious = ops.box_iou(pred_xyxy.to(pred.device), gt_xyxy.to(pred.device))  # note shape: (N, M)\nprint(\"IoU shape (N, M):\", ious.shape)\nprint(\"max IoU overall:\", ious.max().item())\nprint(\"max IoU per GT (cpu):\", ious.max(dim=0).values.cpu().numpy())\nprint(\"max IoU per pred (cpu):\", ious.max(dim=1).values.cpu().numpy()[:20])  # first 20 preds\n\nconf_th = 0.3   # same as your compute_recall\nscores = pred[:, 4].clone()\n# if these are logits, convert to probs for human inspection:\nif scores.min() < 0 or scores.max() > 1:\n    scores = torch.sigmoid(scores)\n\nkeep_conf_mask = scores > conf_th\nprint(\"num preds above conf_th:\", keep_conf_mask.sum().item(), \"out of\", pred.shape[0])\nprint(\"scores above conf sample:\", scores[keep_conf_mask][:20].cpu().numpy())\n\n# optional NMS check\nif keep_conf_mask.sum() > 0:\n    kept_indices = keep_conf_mask.nonzero(as_tuple=False).squeeze(1)\n    boxes_keep = pred_xyxy[kept_indices]\n    scores_keep = scores[kept_indices].cpu()\n    keep_nms = ops.nms(boxes_keep, scores_keep, iou_threshold=0.5)\n    print(\"after NMS kept:\", keep_nms.numel())\nelse:\n    print(\"no preds above conf_th\")\n\n# predicted class ids\np_cls = pred[:, 5:].argmax(dim=-1)\nprint(\"pred classes unique:\", torch.unique(p_cls)[:20].cpu().numpy())\n\n# gt class ids\ngt_cls = gt[:, 4].long()\nprint(\"gt classes unique:\", torch.unique(gt_cls)[:20].cpu().numpy())\n\n# sample equality check for top preds:\nif pred.shape[0] and gt.shape[0]:\n    print(\"sample pred cls, sample gt cls:\", p_cls[:5].cpu().numpy(), gt_cls[:5].cpu().numpy())\n\nrecall_loose = compute_recall([pred.to(device)], [gt.to(device)], iou_th=0.1, conf_th=0.01)\nprint(\"recall with iou=0.1 conf=0.01:\", recall_loose","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-27T22:26:21.655175Z","iopub.execute_input":"2025-08-27T22:26:21.655492Z","iopub.status.idle":"2025-08-27T22:26:24.470145Z","shell.execute_reply.started":"2025-08-27T22:26:21.655441Z","shell.execute_reply":"2025-08-27T22:26:24.469481Z"}},"outputs":[{"name":"stdout","text":"num_preds, num_gt: 25200 7\npred (cx,cy,w,h,obj) sample rows (first 10):\ntensor([[ 4.1210,  4.0072,  2.5521,  3.6273,  0.4887,  0.5119],\n        [12.1210,  4.0072,  2.5521,  3.6273,  0.4887,  0.5119],\n        [20.1210,  4.0072,  2.5521,  3.6273,  0.4887,  0.5119],\n        [28.1210,  4.0072,  2.5521,  3.6273,  0.4887,  0.5119],\n        [36.1210,  4.0072,  2.5521,  3.6273,  0.4887,  0.5119],\n        [44.1210,  4.0072,  2.5521,  3.6273,  0.4887,  0.5119],\n        [52.1210,  4.0072,  2.5521,  3.6273,  0.4887,  0.5119],\n        [60.1210,  4.0072,  2.5521,  3.6273,  0.4887,  0.5119],\n        [68.1210,  4.0072,  2.5521,  3.6273,  0.4887,  0.5119],\n        [76.1210,  4.0072,  2.5521,  3.6273,  0.4887,  0.5119]])\ngt (cx,cy,w,h,cls) sample rows (first 10):\ntensor([[439.4546, 326.1570,  52.9649,  55.8965,   2.0000],\n        [485.1606, 323.2693,  50.1255,  46.9270,   2.0000],\n        [356.3400, 306.9925,  28.7468,  27.1497,   2.0000],\n        [189.6987, 291.0221,  30.5434,  35.1349,   2.0000],\n        [543.7220, 339.9913,  52.7047,  46.8330,   2.0000],\n        [603.1469, 351.8863,  72.3979,  81.8023,   2.0000],\n        [141.7823, 285.1546,  65.1203,  56.4566,   2.0000]])\npred obj min/max: 0.48347944021224976 0.5063170194625854\npred class logits min/max: 0.47840654850006104 0.5209926962852478\nIoU shape (N, M): torch.Size([25200, 7])\nmax IoU overall: 0.6045826077461243\nmax IoU per GT (cpu): [0.53395826 0.56766725 0.5308338  0.5536801  0.55619174 0.5199041\n 0.6045826 ]\nmax IoU per pred (cpu): [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\nnum preds above conf_th: 25200 out of 25200\nscores above conf sample: [0.4886564  0.4886571  0.48865673 0.4886566  0.4886566  0.48865673\n 0.48865652 0.48865673 0.4886566  0.4886566  0.4886566  0.48865697\n 0.4886566  0.4886566  0.4886566  0.48865673 0.48865673 0.4886566\n 0.4886566  0.4886566 ]\nafter NMS kept: 24985\npred classes unique: [1 2 3 5 6 7]\ngt classes unique: [2]\nsample pred cls, sample gt cls: [6 6 6 6 6] [2 2 2 2 2]\nrecall with iou=0.1 conf=0.01: tensor(0.2857)\n","output_type":"stream"}],"execution_count":92}]}